
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="An all-in-one library for topic modeling with sentence embeddings.">
      
      
      
      
        <link rel="prev" href="..">
      
      
        <link rel="next" href="../model_interpretation/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.6">
    
    
      
        <title>Defining and Fitting Topic Models - Turftopic</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.50c56a3b.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="#01034A" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#defining-and-training-topic-models" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Turftopic" class="md-header__button md-logo" aria-label="Turftopic" data-md-component="logo">
      
  <img src="../images/logo.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Turftopic
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Defining and Fitting Topic Models
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
    
      <div class="md-header__source">
        <a href="https://github.com/x-tabdeveloping/turftopic" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href=".." class="md-tabs__link">
          
  
    
  
  Usage

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../tutorials/overview/" class="md-tabs__link">
          
  
    
  
  Tutorials

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../model_overview/" class="md-tabs__link">
          
  
    
  
  Models

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../encoders/" class="md-tabs__link">
        
  
    
  
  Encoders

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../vectorizers/" class="md-tabs__link">
        
  
    
  
  Vectorizers

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../namers/" class="md-tabs__link">
        
  
    
  
  Namers

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Turftopic" class="md-nav__button md-logo" aria-label="Turftopic" data-md-component="logo">
      
  <img src="../images/logo.svg" alt="logo">

    </a>
    Turftopic
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/x-tabdeveloping/turftopic" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href=".." class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Usage
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_1" id="__nav_1_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            Usage
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Defining and Fitting Topic Models
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Defining and Fitting Topic Models
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#defining-a-model" class="md-nav__link">
    <span class="md-ellipsis">
      Defining a Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-and-inference" class="md-nav__link">
    <span class="md-ellipsis">
      Training and Inference
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../model_interpretation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Interpreting and Visualizing Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../seeded/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Seeded Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dynamic/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dynamic Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../online/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Online Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../hierarchical/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hierarchical Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cross_lingual/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Cross-Lingual Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../multimodal/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multimodal Modeling (BETA)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../finetuning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Modifying and Finetuning Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../persistence/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Saving and Loading
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../topic_data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using TopicData
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Tutorials
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tutorial Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/arxiv_ml/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Analyzing the Landscape of Machine Learning Research
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/religious/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Discourse Analysis on Morality and Religion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/ideologies/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Discovering a Data-driven Political Compass
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/reviews/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Customer Dissatisfaction Analysis
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Models
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../model_overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../s3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Semantic Signal Separation (S³)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../KeyNMF/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    KeyNMF
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../GMM/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GMM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../clustering/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Clustering Models (BERTopic & Top2Vec)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ctm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Autoencoding Models (ZeroShotTM & CombinedTM)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../FASTopic/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FASTopic
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../encoders/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Encoders
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../vectorizers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Vectorizers
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../namers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Namers
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="defining-and-training-topic-models">Defining and Training Topic Models</h1>
<p>In order to start modeling your corpora, you will need to define a topic model.
There are a wide array of available models in Turftopic that all have their unique behaviour.
On the other hand all models will need to have certain components, and have attributes you can adjust to your needs.
This page provides a guide on how to define models, train them, and use them for inference.</p>
<figure>
  <img src="../images/topic_modeling_pipeline.png" width="800px" style="margin-left: auto;margin-right: auto;">
  <figcaption>Components of a Topic Modeling Pipeline</figcaption>
</figure>

<h2 id="defining-a-model">Defining a Model</h2>
<h3 id="1-topic-model">1. <a href="../model_overview/">Topic Model</a></h3>
<p>In order to initialize a model, you will first need to make a choice about which <strong>topic model</strong> you'd like to use.
You might want to have a look at the <a href="../model_overview/">Models</a> page in order to make an informed choice about the topic model you intend to train.</p>
<p>Here are some examples of models you can load and use in the package:</p>
<div class="tabbed-set tabbed-alternate" data-tabs="1:3"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio" /><input id="__tabbed_1_2" name="__tabbed_1" type="radio" /><input id="__tabbed_1_3" name="__tabbed_1" type="radio" /><div class="tabbed-labels"><label for="__tabbed_1_1">KeyNMF</label><label for="__tabbed_1_2">ClusteringTopicModel</label><label for="__tabbed_1_3">SemanticSignalSeparation</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">turftopic</span><span class="w"> </span><span class="kn">import</span> <span class="n">KeyNMF</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">KeyNMF</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">top_n</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">turftopic</span><span class="w"> </span><span class="kn">import</span> <span class="n">ClusteringTopicModel</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ClusteringTopicModel</span><span class="p">(</span><span class="n">n_reduce_to</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">feature_importance</span><span class="o">=</span><span class="s2">&quot;centroid&quot;</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">turftopic</span><span class="w"> </span><span class="kn">import</span> <span class="n">SemanticSignalSeparation</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SemanticSignalSeparation</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">feature_importance</span><span class="o">=</span><span class="s2">&quot;combined&quot;</span><span class="p">)</span>
</code></pre></div>
</div>
</div>
</div>
<h3 id="2-vectorizer">2. <a href="../vectorizers/">Vectorizer</a></h3>
<p>In Turftopic, all Models have a vectorizer component, which is responsible for extracting word content from documents in the corpus.
This means, that a vectorizer also determines which words will be part of the model's vocabulary.
For a more detailed explanation, see the <a href="../vectorizers/">Vectorizers</a> page</p>
<p>The default is scikit-learn's CountVectorizer:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.feature_extraction.text</span><span class="w"> </span><span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">default_vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">min_df</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">stop_words</span><span class="o">=</span><span class="s2">&quot;english&quot;</span><span class="p">)</span>
</code></pre></div>
<p>You can add a custom vectorizer to a topic model upon initializing it,
thereby getting different behaviours. You can for instance use noun-phrases in your model instead of words by using <code>NounPhraseCountVectorizer</code> or estimate parameters for lemmas by using <code>LemmaCountVectorizer</code></p>
<div class="tabbed-set tabbed-alternate" data-tabs="2:3"><input checked="checked" id="__tabbed_2_1" name="__tabbed_2" type="radio" /><input id="__tabbed_2_2" name="__tabbed_2" type="radio" /><input id="__tabbed_2_3" name="__tabbed_2" type="radio" /><div class="tabbed-labels"><label for="__tabbed_2_1">Noun Phrase Extraction</label><label for="__tabbed_2_2">Lemma Extraction</label><label for="__tabbed_2_3">Multilingual Tokenization (Arabic example)</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>turftopic<span class="o">[</span>spacy<span class="o">]</span>
python<span class="w"> </span>-m<span class="w"> </span>spacy<span class="w"> </span>download<span class="w"> </span><span class="s2">&quot;en_core_web_sm&quot;</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">turftopic</span><span class="w"> </span><span class="kn">import</span> <span class="n">KeyNMF</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">turftopic.vectorizers.spacy</span><span class="w"> </span><span class="kn">import</span> <span class="n">NounPhraseCountVectorizer</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">KeyNMF</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">vectorizer</span><span class="o">=</span><span class="n">NounPhraseCountVectorizer</span><span class="p">(</span><span class="s2">&quot;en_core_web_sm&quot;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">print_topics</span><span class="p">()</span>
</code></pre></div>
<table>
<thead>
<tr>
<th>Topic ID</th>
<th>Highest Ranking</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>...</td>
</tr>
<tr>
<td>3</td>
<td>fanaticism, theism, fanatism, all fanatism, theists, strong theism, strong atheism, fanatics, precisely some theists, all theism</td>
</tr>
<tr>
<td>4</td>
<td>religion foundation darwin fish bumper stickers, darwin fish, atheism, 3d plastic fish, fish symbol, atheist books, atheist organizations, negative atheism, positive atheism, atheism index</td>
</tr>
<tr>
<td></td>
<td>...</td>
</tr>
</tbody>
</table>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>turftopic<span class="o">[</span>spacy<span class="o">]</span>
python<span class="w"> </span>-m<span class="w"> </span>spacy<span class="w"> </span>download<span class="w"> </span><span class="s2">&quot;en_core_web_sm&quot;</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">turftopic</span><span class="w"> </span><span class="kn">import</span> <span class="n">KeyNMF</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">turftopic.vectorizers.spacy</span><span class="w"> </span><span class="kn">import</span> <span class="n">LemmaCountVectorizer</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">KeyNMF</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">vectorizer</span><span class="o">=</span><span class="n">LemmaCountVectorizer</span><span class="p">(</span><span class="s2">&quot;en_core_web_sm&quot;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">print_topics</span><span class="p">()</span>
</code></pre></div>
<table>
<thead>
<tr>
<th>Topic ID</th>
<th>Highest Ranking</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>atheist, theist, belief, christians, agnostic, christian, mythology, asimov, abortion, read</td>
</tr>
<tr>
<td>1</td>
<td>morality, moral, immoral, objective, society, animal, natural, societal, murder, morally</td>
</tr>
<tr>
<td></td>
<td>...</td>
</tr>
</tbody>
</table>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">turftopic</span><span class="w"> </span><span class="kn">import</span> <span class="n">KeyNMF</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">turftopic.vectorizers.spacy</span><span class="w"> </span><span class="kn">import</span> <span class="n">TokenCountVectorizer</span>

<span class="c1"># CountVectorizer for Arabic</span>
<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TokenCountVectorizer</span><span class="p">(</span><span class="s2">&quot;ar&quot;</span><span class="p">,</span> <span class="n">min_df</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">KeyNMF</span><span class="p">(</span>
    <span class="n">n_components</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">vectorizer</span><span class="o">=</span><span class="n">vectorizer</span><span class="p">,</span>
    <span class="n">encoder</span><span class="o">=</span><span class="s2">&quot;Omartificial-Intelligence-Space/Arabic-MiniLM-L12-v2-all-nli-triplet&quot;</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
</code></pre></div>
</div>
</div>
</div>
<h3 id="3-encoder">3. <a href="../encoders/">Encoder</a></h3>
<p>Since all models in Turftopic rely on contextual embeddings, you will need to specify a contextual embedding model to use.
The default is <a href="sentence-transformers/all-MiniLM-L6-v2"><code>all-MiniLM-L6-v2</code></a>, which is a very fast and reasonably performant embedding model for English.
You might, however want to use custom embeddings, either because your corpus is not in English, or because you need higher speed or performance.
See a detailed guide on Encoders <a href="../encoders/">here</a>.</p>
<p>Similar to a vectorizer, you can add an encoder to a topic model upon initializing it.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">turftopic</span><span class="w"> </span><span class="kn">import</span> <span class="n">KeyNMF</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sentence_transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">SentenceTransformer</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s2">&quot;parahprase-multilingual-MiniLM-L12-v2&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">KeyNMF</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">)</span>
</code></pre></div>
<h3 id="4-namer-optional">4. <a href="../namers/">Namer</a> (<em>optional</em>)</h3>
<p>A Namer is an optional part of your topic modeling pipeline, that can automatically assign human-readable names to topics.
Namers are technically <strong>not part of your topic model</strong>, and should be used <em>after training</em>.
See a detailed guide <a href="../namers/">here</a>.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="3:2"><input checked="checked" id="__tabbed_3_1" name="__tabbed_3" type="radio" /><input id="__tabbed_3_2" name="__tabbed_3" type="radio" /><div class="tabbed-labels"><label for="__tabbed_3_1">LLM from HuggingFace</label><label for="__tabbed_3_2">ChatGPT</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">turftopic</span><span class="w"> </span><span class="kn">import</span> <span class="n">KeyNMF</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">turftopic.namers</span><span class="w"> </span><span class="kn">import</span> <span class="n">LLMTopicNamer</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">KeyNMF</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="n">namer</span> <span class="o">=</span> <span class="n">LLMTopicNamer</span><span class="p">(</span><span class="s2">&quot;HuggingFaceTB/SmolLM2-1.7B-Instruct&quot;</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">rename_topics</span><span class="p">(</span><span class="n">namer</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<p><div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>openai
<span class="nb">export</span><span class="w"> </span><span class="nv">OPENAI_API_KEY</span><span class="o">=</span><span class="s2">&quot;sk-&lt;your key goes here&gt;&quot;</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">turftopic.namers</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAITopicNamer</span>

<span class="n">namer</span> <span class="o">=</span> <span class="n">OpenAITopicNamer</span><span class="p">(</span><span class="s2">&quot;gpt-4o-mini&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">rename_topics</span><span class="p">(</span><span class="n">namer</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">print_topics</span><span class="p">()</span>
</code></pre></div></p>
<table>
<thead>
<tr>
<th>Topic ID</th>
<th>Topic Name</th>
<th>Highest Ranking</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>Operating Systems and Software</td>
<td>windows, dos, os, ms, microsoft, unix, nt, memory, program, apps</td>
</tr>
<tr>
<td>1</td>
<td>Atheism and Belief Systems</td>
<td>atheism, atheist, atheists, belief, religion, religious, theists, beliefs, believe, faith</td>
</tr>
<tr>
<td></td>
<td>...</td>
<td></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<h2 id="training-and-inference">Training and Inference</h2>
<h3 id="model-training">Model Training</h3>
<p>All models in Turftopic follow a scikit-learn API for fitting topic models.
Every model in the library can be trained by passing a set of documents (a <em>corpus</em>) to the model.
This has to be an <code>Iterable</code> type object, that has to be reusable as models will typically do multiple passes on the corpus.</p>
<div class="highlight"><pre><span></span><code><span class="n">corpus</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;this is a a document&quot;</span><span class="p">,</span> <span class="s2">&quot;this is yet another document&quot;</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
</code></pre></div>
<div class="admonition quote">
<p class="admonition-title">Fit your topic model</p>
<div class="tabbed-set tabbed-alternate" data-tabs="4:3"><input checked="checked" id="__tabbed_4_1" name="__tabbed_4" type="radio" /><input id="__tabbed_4_2" name="__tabbed_4" type="radio" /><input id="__tabbed_4_3" name="__tabbed_4" type="radio" /><div class="tabbed-labels"><label for="__tabbed_4_1"><code>fit(raw_documents, embeddings=None)</code></label><label for="__tabbed_4_2"><code>fit_transform(raw_documents, embeddings=None)</code></label><label for="__tabbed_4_3"><code>prepare_topic_data(corpus, embeddings=None)</code></label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p><code>fit()</code> simply fits the topic model and returns the same model object fitted.
You can optionally pass a set of precomputed embeddings for the documents.</p>
<div class="highlight"><pre><span></span><code><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<p><code>fit_transform()</code> not only trains the model but also returns topic-proportions in all documents in the corpus.
<div class="highlight"><pre><span></span><code><span class="n">document_topic_matrix</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="c1"># or </span>
<span class="n">document_topic_matrix</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">document_topic_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># prints (n_documents, n_topics)</span>
</code></pre></div></p>
</div>
<div class="tabbed-block">
<p><code>prepare_topic_data()</code> not only fits the model (only if not already fitted), but also saves other aspects of topic inference, which makes it easier to then use this object for pretty printing and visualizing your models (see <a href="../model_interpretation/">Model Interpretation</a>)</p>
<p><div class="highlight"><pre><span></span><code><span class="n">topic_data</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">prepare_topic_data</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="c1"># print to see what attributes you can access.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">topic_data</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>TopicData
├── corpus (1000)
├── vocab (1746,)
├── document_term_matrix (1000, 1746)
├── topic_term_matrix (10, 1746)
├── document_topic_matrix (1000, 10)
├── document_representation (1000, 384)
├── transform
├── topic_names (10)
├── has_negative_side
└── hierarchy
</code></pre></div>
See <a href="../topic_data/">Using TopicData</a> for more detail.</p>
</div>
</div>
</div>
</div>
<h3 id="precomputing-embeddings">Precomputing Embeddings</h3>
<p>In order to cut down on costs/computational load when fitting multiple models in a row, you might want to encode the documents before fitting a model.
Encoding the corpus is the heaviest part of the process and you can spare yourself a lot of time by only doing it once.
Some models have to encode the vocabulary as well, this cannot be done before inference, as the models learn the vocabulary itself from the corpus.</p>
<p>The <code>fit()</code> method of all models takes and <code>embeddings</code> argument, that allows you to pass a precooked embedding matrix along to fitting.
One thing to watch out for is that you have to pass the embedding model along to the model that was used for encoding the corpus.
This is again, to ensure that the vocabulary gets encoded with the same embedding model as the documents.</p>
<p>Here's a snippet of correct usage:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sentence_transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">SentenceTransformer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">turftopic</span><span class="w"> </span><span class="kn">import</span> <span class="n">GMM</span><span class="p">,</span> <span class="n">ClusteringTopicModel</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s2">&quot;intfloat/e5-large-v2&quot;</span><span class="p">,</span> <span class="n">prompts</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="s2">&quot;query: &quot;</span><span class="p">,</span> <span class="s2">&quot;passage&quot;</span><span class="p">:</span> <span class="s2">&quot;passage: &quot;</span><span class="p">},</span> <span class="n">default_prompt_name</span><span class="o">=</span><span class="s2">&quot;query&quot;</span><span class="p">)</span>

<span class="n">corpus</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;this is a a document&quot;</span><span class="p">,</span> <span class="s2">&quot;this is yet another document&quot;</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">corpus</span><span class="p">))</span>

<span class="n">gmm</span> <span class="o">=</span> <span class="n">GMM</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span><span class="p">)</span>

<span class="n">clustering</span> <span class="o">=</span> <span class="n">ClusteringTopicModel</span><span class="p">(</span><span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span><span class="p">)</span>
</code></pre></div>
<h3 id="inference">Inference</h3>
<p>Some models in Turftopic are capable of estimating topic importance scores for documents in your corpus.
In order to get the importance of each topic for the documents in the corpus, you might want to use <code>fit_transform()</code> instead of <code>fit()</code></p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Note that using <code>fit()</code> and <code>transform()</code> in succession is not the same as using <code>fit_transform()</code> and the later should be preferred under all circumstances.
For one, not all models have a <code>transform()</code> method, but <code>fit_transform()</code> is also way more efficient, as documents don't have to be encoded twice.
Some models have additional optimizations going on when using <code>fit_transform()</code>, and the <code>fit()</code> method typically uses <code>fit_transform()</code> in the background.</p>
</div>
<div class="highlight"><pre><span></span><code><span class="n">document_topic_matrix</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
</code></pre></div>
<p>This will give you a matrix, where every row is a document and every column represents the importance of a given topic.</p>
<p>You can infer topical content for new documents with a fitted model using the <code>transform()</code> method (beware that this only works with inductive methods):</p>
<div class="highlight"><pre><span></span><code><span class="n">document_topic_matrix</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">new_documents</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["toc.integrate", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.path", "navigation.indexes", "toc.follow", "content.code.copy"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.e1c3ead8.min.js"></script>
      
        <script src="../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>