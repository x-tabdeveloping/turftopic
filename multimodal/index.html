
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="An all-in-one library for topic modeling with sentence embeddings.">
      
      
      
      
        <link rel="prev" href="../cross_lingual/">
      
      
        <link rel="next" href="../finetuning/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.6">
    
    
      
        <title>Multimodal Modeling (BETA) - Turftopic</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.50c56a3b.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="#01034A" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#multimodal-topic-modelling-beta" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Turftopic" class="md-header__button md-logo" aria-label="Turftopic" data-md-component="logo">
      
  <img src="../images/logo.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Turftopic
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Multimodal Modeling (BETA)
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
    
      <div class="md-header__source">
        <a href="https://github.com/x-tabdeveloping/turftopic" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href=".." class="md-tabs__link">
          
  
    
  
  Usage

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../tutorials/overview/" class="md-tabs__link">
          
  
    
  
  Tutorials

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../model_overview/" class="md-tabs__link">
          
  
    
  
  Models

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../encoders/" class="md-tabs__link">
        
  
    
  
  Encoders

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../vectorizers/" class="md-tabs__link">
        
  
    
  
  Vectorizers

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../namers/" class="md-tabs__link">
        
  
    
  
  Namers

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Turftopic" class="md-nav__button md-logo" aria-label="Turftopic" data-md-component="logo">
      
  <img src="../images/logo.svg" alt="logo">

    </a>
    Turftopic
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/x-tabdeveloping/turftopic" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href=".." class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Usage
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_1" id="__nav_1_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            Usage
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../model_definition_and_training/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Defining and Fitting Topic Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../model_interpretation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Interpreting and Visualizing Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../seeded/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Seeded Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dynamic/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dynamic Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../online/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Online Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../hierarchical/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hierarchical Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cross_lingual/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Cross-Lingual Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Multimodal Modeling (BETA)
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Multimodal Modeling (BETA)
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#multimodal-encoders" class="md-nav__link">
    <span class="md-ellipsis">
      Multimodal Encoders
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#corpus-structure" class="md-nav__link">
    <span class="md-ellipsis">
      Corpus Structure
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#basic-usage" class="md-nav__link">
    <span class="md-ellipsis">
      Basic Usage
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#api-reference" class="md-nav__link">
    <span class="md-ellipsis">
      API reference
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../finetuning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Modifying and Finetuning Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../persistence/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Saving and Loading
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../topic_data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using TopicData
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Tutorials
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tutorial Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/arxiv_ml/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Analyzing the Landscape of Machine Learning Research
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/religious/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Discourse Analysis on Morality and Religion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/ideologies/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Discovering a Data-driven Political Compass
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/reviews/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Customer Dissatisfaction Analysis
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Models
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../model_overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../s3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Semantic Signal Separation (S³)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../KeyNMF/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    KeyNMF
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../GMM/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GMM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../clustering/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Clustering Models (BERTopic & Top2Vec)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ctm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Autoencoding Models (ZeroShotTM & CombinedTM)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../FASTopic/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FASTopic
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../encoders/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Encoders
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../vectorizers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Vectorizers
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../namers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Namers
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="multimodal-topic-modelling-beta">Multimodal Topic Modelling <strong><em>(BETA)</em></strong></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Multimodal modeling is still a BETA feature in Turftopic, and it is likely that we will add more features and change the interface in the near future.</p>
</div>
<p>Some corpora spread across multiple modalities.
A good example of this would be news articles with images attached.
Turftopic now supports multimodal modelling with a number of models.</p>
<h2 id="multimodal-encoders">Multimodal Encoders</h2>
<p>In order for images to be usable in Turftopic, you will need an embedding model that can both encode texts and images.
You can both use models that are supported in SentenceTransformers, or those that support the MTEB multimodal encoder interface.</p>
<div class="admonition quote">
<p class="admonition-title">Use a multimodal encoder model </p>
<div class="tabbed-set tabbed-alternate" data-tabs="1:2"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio" /><input id="__tabbed_1_2" name="__tabbed_1" type="radio" /><div class="tabbed-labels"><label for="__tabbed_1_1">SentenceTransformers</label><label for="__tabbed_1_2">MTEB/MIEB</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">turftopic</span><span class="w"> </span><span class="kn">import</span> <span class="n">KeyNMF</span>

<span class="n">multimodal_keynmf</span> <span class="o">=</span> <span class="n">KeyNMF</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">encoder</span><span class="o">=</span><span class="s2">&quot;clip-ViT-B-32&quot;</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>You can find current state-of-the-art embedding models and their capabilities on the <a href="http://mteb-leaderboard.hf.space/?benchmark_name=MIEB%28Multilingual%29">Massive Image Embedding Benchmark leaderboard</a>.</p>
</div>
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span><span class="s2">&quot;mteb&lt;2.0.0&quot;</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">turftopic</span><span class="w"> </span><span class="kn">import</span> <span class="n">KeyNMF</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">mteb</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">mteb</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="s2">&quot;kakaobrain/align-base&quot;</span><span class="p">)</span>

<span class="n">multimodal_keynmf</span> <span class="o">=</span> <span class="n">KeyNMF</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">encoder</span><span class="o">=</span><span class="s2">&quot;clip-ViT-B-32&quot;</span><span class="p">)</span>
</code></pre></div>
</div>
</div>
</div>
</div>
<h2 id="corpus-structure">Corpus Structure</h2>
<p>Currently all documents <strong>have to have</strong> an image attached to them, and only one image.
This is a limitation, and we will address it in the future.
Images can both be represented as file paths or <code>PIL.Image</code> objects.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>

<span class="n">images</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Image</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;file_path/something.jpeg&quot;</span><span class="p">),</span> <span class="o">...</span><span class="p">]</span>
<span class="n">texts</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="o">...</span><span class="p">]</span>

<span class="nb">len</span><span class="p">(</span><span class="n">images</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">texts</span><span class="p">)</span>
</code></pre></div>
<h2 id="basic-usage">Basic Usage</h2>
<p>All multimodal models have a <code>fit_multimodal()</code>/<code>fit_transform_multimodal()</code> method,
that you can use to discover topics in multimodal corpora.</p>
<div class="admonition quote">
<p class="admonition-title">Fit a multimodal model on a corpus</p>
<div class="tabbed-set tabbed-alternate" data-tabs="2:5"><input checked="checked" id="__tabbed_2_1" name="__tabbed_2" type="radio" /><input id="__tabbed_2_2" name="__tabbed_2" type="radio" /><input id="__tabbed_2_3" name="__tabbed_2" type="radio" /><input id="__tabbed_2_4" name="__tabbed_2" type="radio" /><input id="__tabbed_2_5" name="__tabbed_2" type="radio" /><div class="tabbed-labels"><label for="__tabbed_2_1">SemanticSignalSeparation</label><label for="__tabbed_2_2">KeyNMF</label><label for="__tabbed_2_3">Clustering Models</label><label for="__tabbed_2_4">GMM</label><label for="__tabbed_2_5">AutoEncodingTopicModel</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">turftopic</span><span class="w"> </span><span class="kn">import</span> <span class="n">SemanticSignalSeparation</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SemanticSignalSeparation</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="n">encoder</span><span class="o">=</span><span class="s2">&quot;clip-ViT-B-32&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit_multimodal</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">images</span><span class="o">=</span><span class="n">images</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">plot_multimodal_topics</span><span class="p">()</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">turftopic</span><span class="w"> </span><span class="kn">import</span> <span class="n">KeyNMF</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">KeyNMF</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="n">encoder</span><span class="o">=</span><span class="s2">&quot;clip-ViT-B-32&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit_multimodal</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">images</span><span class="o">=</span><span class="n">images</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">plot_multimodal_topics</span><span class="p">()</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">turftopic</span><span class="w"> </span><span class="kn">import</span> <span class="n">ClusteringTopicModel</span>

<span class="c1"># BERTopic-style</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ClusteringTopicModel</span><span class="p">(</span><span class="n">encoder</span><span class="o">=</span><span class="s2">&quot;clip-ViT-B-32&quot;</span><span class="p">,</span> <span class="n">feature_importance</span><span class="o">=</span><span class="s2">&quot;c-tf-idf&quot;</span><span class="p">)</span>
<span class="c1"># Top2Vec-style</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ClusteringTopicModel</span><span class="p">(</span><span class="n">encoder</span><span class="o">=</span><span class="s2">&quot;clip-ViT-B-32&quot;</span><span class="p">,</span> <span class="n">feature_importance</span><span class="o">=</span><span class="s2">&quot;centroid&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit_multimodal</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">images</span><span class="o">=</span><span class="n">images</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">plot_multimodal_topics</span><span class="p">()</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">turftopic</span><span class="w"> </span><span class="kn">import</span> <span class="n">GMM</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">GMM</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="n">encoder</span><span class="o">=</span><span class="s2">&quot;clip-ViT-B-32&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit_multimodal</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">images</span><span class="o">=</span><span class="n">images</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">plot_multimodal_topics</span><span class="p">()</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">turftopic</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoEncodingTopicModel</span>

<span class="c1"># CombinedTM</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoEncodingTopicModel</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="n">combined</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">encoder</span><span class="o">=</span><span class="s2">&quot;clip-ViT-B-32&quot;</span><span class="p">)</span>
<span class="c1"># ZeroShotTM</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoEncodingTopicModel</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="n">combined</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">encoder</span><span class="o">=</span><span class="s2">&quot;clip-ViT-B-32&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit_multimodal</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">images</span><span class="o">=</span><span class="n">images</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">plot_multimodal_topics</span><span class="p">()</span>
</code></pre></div>
</div>
</div>
</div>
</div>
<iframe src="../images/multimodal.html", title="Multimodal S^3 on IKEA catalogue", style="height:800px;width:1200px;padding:0px;border:none;"></iframe>

<h2 id="api-reference">API reference</h2>


<div class="doc doc-object doc-class">



<h3 id="turftopic.multimodal.MultimodalModel" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>          <code>turftopic.multimodal.MultimodalModel</code>


</h3>


  <div class="doc doc-contents first">

  
      <p>Base model for multimodal topic models.</p>

            <details class="quote">
              <summary>Source code in <code>turftopic/multimodal.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">MultimodalModel</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Base model for multimodal topic models.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">encode_multimodal</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">sentences</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">images</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">ImageRepr</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Produce multimodal embeddings of the documents passed to the model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        sentences: list[str]</span>
<span class="sd">            Textual documents to encode.</span>
<span class="sd">        images: list[ImageRepr]</span>
<span class="sd">            Corresponding images for each document.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        MultimodalEmbeddings</span>
<span class="sd">            Text, image and joint document embeddings.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">encode_multimodal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder_</span><span class="p">,</span> <span class="n">sentences</span><span class="p">,</span> <span class="n">images</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">validate_embeddings</span><span class="p">(</span><span class="n">embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MultimodalEmbeddings</span><span class="p">]):</span>
        <span class="k">if</span> <span class="n">embeddings</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">document_embeddings</span> <span class="o">=</span> <span class="n">embeddings</span><span class="p">[</span><span class="s2">&quot;document_embeddings&quot;</span><span class="p">]</span>
            <span class="n">image_embeddings</span> <span class="o">=</span> <span class="n">embeddings</span><span class="p">[</span><span class="s2">&quot;image_embeddings&quot;</span><span class="p">]</span>
        <span class="k">except</span> <span class="ne">KeyError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;embeddings do not contain document and image embeddings, can&#39;t be used for multimodal modelling.&quot;</span>
            <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
        <span class="k">if</span> <span class="n">document_embeddings</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">image_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Shape mismatch between document_embeddings </span><span class="si">{</span><span class="n">document_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> and image_embeddings </span><span class="si">{</span><span class="n">image_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">validate_encoder</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder_</span><span class="p">,</span> <span class="s2">&quot;encode&quot;</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span>
                <span class="p">(</span>
                    <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder_</span><span class="p">,</span> <span class="s2">&quot;get_text_embeddings&quot;</span><span class="p">),</span>
                    <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder_</span><span class="p">,</span> <span class="s2">&quot;get_image_embeddings&quot;</span><span class="p">),</span>
                <span class="p">),</span>
            <span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="s2">&quot;An encoder must either have an encode() method or a get_text_embeddings and get_image_embeddings method (optionally get_fused_embeddings)&quot;</span>
                <span class="p">)</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit_transform_multimodal</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">raw_documents</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">images</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">ImageRepr</span><span class="p">],</span>
        <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MultimodalEmbeddings</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Fits topic model in a multimodal context and returns the document-topic matrix.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        raw_documents: iterable of str</span>
<span class="sd">            Documents to fit the model on.</span>
<span class="sd">        images: list[ImageRepr]</span>
<span class="sd">            Images corresponding to each document.</span>
<span class="sd">        y: None</span>
<span class="sd">            Ignored, exists for sklearn compatibility.</span>
<span class="sd">        embeddings: MultimodalEmbeddings</span>
<span class="sd">            Precomputed multimodal embeddings.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ndarray of shape (n_documents, n_topics)</span>
<span class="sd">            Document-topic matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">fit_multimodal</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">raw_documents</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">images</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">ImageRepr</span><span class="p">],</span>
        <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MultimodalEmbeddings</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Fits topic model on a multimodal corpus.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        raw_documents: iterable of str</span>
<span class="sd">            Documents to fit the model on.</span>
<span class="sd">        images: list[ImageRepr]</span>
<span class="sd">            Images corresponding to each document.</span>
<span class="sd">        y: None</span>
<span class="sd">            Ignored, exists for sklearn compatibility.</span>
<span class="sd">        embeddings: MultimodalEmbeddings</span>
<span class="sd">            Precomputed multimodal embeddings.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Self</span>
<span class="sd">            The fitted topic model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_transform_multimodal</span><span class="p">(</span><span class="n">raw_documents</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">collect_top_images</span><span class="p">(</span>
        <span class="n">images</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">],</span>
        <span class="n">image_topic_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">n_images</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
        <span class="n">negative</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">]]:</span>
        <span class="n">top_images</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">image_topic_vector</span> <span class="ow">in</span> <span class="n">image_topic_matrix</span><span class="o">.</span><span class="n">T</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">negative</span><span class="p">:</span>
                <span class="n">image_topic_vector</span> <span class="o">=</span> <span class="o">-</span><span class="n">image_topic_vector</span>
            <span class="n">top_im_ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="o">-</span><span class="n">image_topic_vector</span><span class="p">)[:</span><span class="mi">20</span><span class="p">]</span>
            <span class="n">top_im</span> <span class="o">=</span> <span class="p">[</span><span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">top_im_ind</span><span class="p">]</span>
            <span class="n">top_images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">top_im</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">top_images</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">prepare_multimodal_topic_data</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">corpus</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">images</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">ImageRepr</span><span class="p">],</span>
        <span class="n">embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MultimodalEmbeddings</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TopicData</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Produces multimodal topic inference data for a given corpus, that can be then used and reused.</span>
<span class="sd">        Exists to allow visualizations out of the box with topicwizard.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        corpus: list[str]</span>
<span class="sd">            Documents to infer topical content for.</span>
<span class="sd">        images: list[ImageRepr]</span>
<span class="sd">            Images belonging to the documents.</span>
<span class="sd">        embeddings: MultimodalEmbeddings</span>
<span class="sd">            Embeddings of documents.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        TopicData</span>
<span class="sd">            Information about topical inference in a dictionary.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">embeddings</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode_multimodal</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">images</span><span class="p">)</span>
        <span class="n">document_topic_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_transform_multimodal</span><span class="p">(</span>
            <span class="n">corpus</span><span class="p">,</span> <span class="n">images</span><span class="o">=</span><span class="n">images</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span>
        <span class="p">)</span>
        <span class="n">dtm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">classes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="n">classes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">components_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">TopicData</span><span class="p">(</span>
            <span class="n">corpus</span><span class="o">=</span><span class="n">corpus</span><span class="p">,</span>
            <span class="n">document_term_matrix</span><span class="o">=</span><span class="n">dtm</span><span class="p">,</span>
            <span class="n">vocab</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">get_vocab</span><span class="p">(),</span>
            <span class="n">document_topic_matrix</span><span class="o">=</span><span class="n">document_topic_matrix</span><span class="p">,</span>
            <span class="n">document_representation</span><span class="o">=</span><span class="n">embeddings</span><span class="p">[</span><span class="s2">&quot;document_embeddings&quot;</span><span class="p">],</span>
            <span class="n">topic_term_matrix</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">components_</span><span class="p">,</span>  <span class="c1"># type: ignore</span>
            <span class="n">transform</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;transform&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
            <span class="n">topic_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">topic_names</span><span class="p">,</span>
            <span class="n">classes</span><span class="o">=</span><span class="n">classes</span><span class="p">,</span>
            <span class="n">has_negative_side</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">has_negative_side</span><span class="p">,</span>
            <span class="n">hierarchy</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;hierarchy&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
            <span class="n">images</span><span class="o">=</span><span class="n">images</span><span class="p">,</span>
            <span class="n">top_images</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">top_images</span><span class="p">,</span>
            <span class="n">negative_images</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;negative_images&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h4 id="turftopic.multimodal.MultimodalModel.encode_multimodal" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>          <code class="highlight language-python"><span class="n">encode_multimodal</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">images</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Produce multimodal embeddings of the documents passed to the model.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>sentences</code></td>
          <td>
                <code>list[str]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Textual documents to encode.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>images</code></td>
          <td>
                <code>list[<span title="turftopic.multimodal.ImageRepr">ImageRepr</span>]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Corresponding images for each document.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>



  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><span title="turftopic.multimodal.MultimodalEmbeddings">MultimodalEmbeddings</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Text, image and joint document embeddings.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>turftopic/multimodal.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">encode_multimodal</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">sentences</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">images</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">ImageRepr</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Produce multimodal embeddings of the documents passed to the model.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sentences: list[str]</span>
<span class="sd">        Textual documents to encode.</span>
<span class="sd">    images: list[ImageRepr]</span>
<span class="sd">        Corresponding images for each document.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    MultimodalEmbeddings</span>
<span class="sd">        Text, image and joint document embeddings.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">encode_multimodal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder_</span><span class="p">,</span> <span class="n">sentences</span><span class="p">,</span> <span class="n">images</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="turftopic.multimodal.MultimodalModel.fit_multimodal" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>          <code class="highlight language-python"><span class="n">fit_multimodal</span><span class="p">(</span><span class="n">raw_documents</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Fits topic model on a multimodal corpus.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>raw_documents</code></td>
          <td>
                <code>list[str]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Documents to fit the model on.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>images</code></td>
          <td>
                <code>list[<span title="turftopic.multimodal.ImageRepr">ImageRepr</span>]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Images corresponding to each document.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>y</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Ignored, exists for sklearn compatibility.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>embeddings</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[<span title="turftopic.multimodal.MultimodalEmbeddings">MultimodalEmbeddings</span>]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Precomputed multimodal embeddings.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>



  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>Self</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The fitted topic model</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>turftopic/multimodal.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">fit_multimodal</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">raw_documents</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">images</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">ImageRepr</span><span class="p">],</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MultimodalEmbeddings</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Fits topic model on a multimodal corpus.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    raw_documents: iterable of str</span>
<span class="sd">        Documents to fit the model on.</span>
<span class="sd">    images: list[ImageRepr]</span>
<span class="sd">        Images corresponding to each document.</span>
<span class="sd">    y: None</span>
<span class="sd">        Ignored, exists for sklearn compatibility.</span>
<span class="sd">    embeddings: MultimodalEmbeddings</span>
<span class="sd">        Precomputed multimodal embeddings.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Self</span>
<span class="sd">        The fitted topic model</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fit_transform_multimodal</span><span class="p">(</span><span class="n">raw_documents</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="turftopic.multimodal.MultimodalModel.fit_transform_multimodal" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>          <code class="highlight language-python"><span class="n">fit_transform_multimodal</span><span class="p">(</span><span class="n">raw_documents</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

</h4>


  <div class="doc doc-contents ">
  
      <p>Fits topic model in a multimodal context and returns the document-topic matrix.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>raw_documents</code></td>
          <td>
                <code>list[str]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Documents to fit the model on.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>images</code></td>
          <td>
                <code>list[<span title="turftopic.multimodal.ImageRepr">ImageRepr</span>]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Images corresponding to each document.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>y</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Ignored, exists for sklearn compatibility.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>embeddings</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[<span title="turftopic.multimodal.MultimodalEmbeddings">MultimodalEmbeddings</span>]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Precomputed multimodal embeddings.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>



  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>ndarray of shape (n_documents, n_topics)</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Document-topic matrix.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>turftopic/multimodal.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@abstractmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">fit_transform_multimodal</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">raw_documents</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">images</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">ImageRepr</span><span class="p">],</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MultimodalEmbeddings</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Fits topic model in a multimodal context and returns the document-topic matrix.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    raw_documents: iterable of str</span>
<span class="sd">        Documents to fit the model on.</span>
<span class="sd">    images: list[ImageRepr]</span>
<span class="sd">        Images corresponding to each document.</span>
<span class="sd">    y: None</span>
<span class="sd">        Ignored, exists for sklearn compatibility.</span>
<span class="sd">    embeddings: MultimodalEmbeddings</span>
<span class="sd">        Precomputed multimodal embeddings.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ndarray of shape (n_documents, n_topics)</span>
<span class="sd">        Document-topic matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">pass</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="turftopic.multimodal.MultimodalModel.prepare_multimodal_topic_data" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>          <code class="highlight language-python"><span class="n">prepare_multimodal_topic_data</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Produces multimodal topic inference data for a given corpus, that can be then used and reused.
Exists to allow visualizations out of the box with topicwizard.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>corpus</code></td>
          <td>
                <code>list[str]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Documents to infer topical content for.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>images</code></td>
          <td>
                <code>list[<span title="turftopic.multimodal.ImageRepr">ImageRepr</span>]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Images belonging to the documents.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>embeddings</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[<span title="turftopic.multimodal.MultimodalEmbeddings">MultimodalEmbeddings</span>]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Embeddings of documents.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>



  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><a class="autorefs autorefs-internal" title="turftopic.data.TopicData" href="../topic_data/#turftopic.data.TopicData">TopicData</a></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Information about topical inference in a dictionary.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>turftopic/multimodal.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">prepare_multimodal_topic_data</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">corpus</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">images</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">ImageRepr</span><span class="p">],</span>
    <span class="n">embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MultimodalEmbeddings</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TopicData</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Produces multimodal topic inference data for a given corpus, that can be then used and reused.</span>
<span class="sd">    Exists to allow visualizations out of the box with topicwizard.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    corpus: list[str]</span>
<span class="sd">        Documents to infer topical content for.</span>
<span class="sd">    images: list[ImageRepr]</span>
<span class="sd">        Images belonging to the documents.</span>
<span class="sd">    embeddings: MultimodalEmbeddings</span>
<span class="sd">        Embeddings of documents.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    TopicData</span>
<span class="sd">        Information about topical inference in a dictionary.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">embeddings</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode_multimodal</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">images</span><span class="p">)</span>
    <span class="n">document_topic_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_transform_multimodal</span><span class="p">(</span>
        <span class="n">corpus</span><span class="p">,</span> <span class="n">images</span><span class="o">=</span><span class="n">images</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span>
    <span class="p">)</span>
    <span class="n">dtm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">classes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span>
    <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
        <span class="n">classes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">components_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">TopicData</span><span class="p">(</span>
        <span class="n">corpus</span><span class="o">=</span><span class="n">corpus</span><span class="p">,</span>
        <span class="n">document_term_matrix</span><span class="o">=</span><span class="n">dtm</span><span class="p">,</span>
        <span class="n">vocab</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">get_vocab</span><span class="p">(),</span>
        <span class="n">document_topic_matrix</span><span class="o">=</span><span class="n">document_topic_matrix</span><span class="p">,</span>
        <span class="n">document_representation</span><span class="o">=</span><span class="n">embeddings</span><span class="p">[</span><span class="s2">&quot;document_embeddings&quot;</span><span class="p">],</span>
        <span class="n">topic_term_matrix</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">components_</span><span class="p">,</span>  <span class="c1"># type: ignore</span>
        <span class="n">transform</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;transform&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
        <span class="n">topic_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">topic_names</span><span class="p">,</span>
        <span class="n">classes</span><span class="o">=</span><span class="n">classes</span><span class="p">,</span>
        <span class="n">has_negative_side</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">has_negative_side</span><span class="p">,</span>
        <span class="n">hierarchy</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;hierarchy&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
        <span class="n">images</span><span class="o">=</span><span class="n">images</span><span class="p">,</span>
        <span class="n">top_images</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">top_images</span><span class="p">,</span>
        <span class="n">negative_images</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;negative_images&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>

<div class="doc doc-object doc-class">



<h3 id="turftopic.encoders.multimodal.MultimodalEncoder" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>          <code>turftopic.encoders.multimodal.MultimodalEncoder</code>


</h3>


  <div class="doc doc-contents first">
          <p class="doc doc-class-bases">
            Bases: <code><span title="typing.Protocol">Protocol</span></code></p>

  
      <p>Base class for external encoder models.</p>

            <details class="quote">
              <summary>Source code in <code>turftopic/encoders/multimodal.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">MultimodalEncoder</span><span class="p">(</span><span class="n">Protocol</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Base class for external encoder models.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_text_embeddings</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">texts</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span> <span class="o">...</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_image_embeddings</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">images</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span> <span class="o">...</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_fused_embeddings</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">texts</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">images</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span> <span class="o">...</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">











  </div>

  </div>


</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["toc.integrate", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.path", "navigation.indexes", "toc.follow", "content.code.copy"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.e1c3ead8.min.js"></script>
      
        <script src="../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>