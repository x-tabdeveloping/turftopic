
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="An all-in-one library for topic modeling with sentence embeddings.">
      
      
      
      
        <link rel="prev" href="../s3/">
      
      
        <link rel="next" href="../GMM/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.6">
    
    
      
        <title>KeyNMF - Turftopic</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.50c56a3b.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="#01034A" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#keynmf" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Turftopic" class="md-header__button md-logo" aria-label="Turftopic" data-md-component="logo">
      
  <img src="../images/logo.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Turftopic
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              KeyNMF
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
    
      <div class="md-header__source">
        <a href="https://github.com/x-tabdeveloping/turftopic" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href=".." class="md-tabs__link">
          
  
    
  
  Usage

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../tutorials/overview/" class="md-tabs__link">
          
  
    
  
  Tutorials

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../model_overview/" class="md-tabs__link">
          
  
    
  
  Models

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../encoders/" class="md-tabs__link">
        
  
    
  
  Encoders

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../vectorizers/" class="md-tabs__link">
        
  
    
  
  Vectorizers

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../namers/" class="md-tabs__link">
        
  
    
  
  Namers

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Turftopic" class="md-nav__button md-logo" aria-label="Turftopic" data-md-component="logo">
      
  <img src="../images/logo.svg" alt="logo">

    </a>
    Turftopic
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/x-tabdeveloping/turftopic" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href=".." class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Usage
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_1" id="__nav_1_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            Usage
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../model_definition_and_training/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Defining and Fitting Topic Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../model_interpretation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Interpreting and Visualizing Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../seeded/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Seeded Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dynamic/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dynamic Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../online/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Online Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../hierarchical/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hierarchical Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cross_lingual/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Cross-Lingual Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../multimodal/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multimodal Modeling (BETA)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../finetuning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Modifying and Finetuning Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../persistence/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Saving and Loading
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../topic_data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using TopicData
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Tutorials
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tutorial Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/arxiv_ml/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Analyzing the Landscape of Machine Learning Research
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/religious/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Discourse Analysis on Morality and Religion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/ideologies/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Discovering a Data-driven Political Compass
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/reviews/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Customer Dissatisfaction Analysis
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Models
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../model_overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../s3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Semantic Signal Separation (S³)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    KeyNMF
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    KeyNMF
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#how-does-keynmf-work" class="md-nav__link">
    <span class="md-ellipsis">
      How does KeyNMF work?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#seeded-topic-modeling" class="md-nav__link">
    <span class="md-ellipsis">
      Seeded Topic Modeling
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dynamic-topic-modeling" class="md-nav__link">
    <span class="md-ellipsis">
      Dynamic Topic Modeling
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hierarchical-topic-modeling" class="md-nav__link">
    <span class="md-ellipsis">
      Hierarchical Topic Modeling
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cross-lingual-keynmf" class="md-nav__link">
    <span class="md-ellipsis">
      Cross-lingual KeyNMF
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#online-topic-modeling" class="md-nav__link">
    <span class="md-ellipsis">
      Online Topic Modeling
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#asymmetric-and-instruction-tuned-embedding-models" class="md-nav__link">
    <span class="md-ellipsis">
      Asymmetric and Instruction-tuned Embedding Models
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#api-reference" class="md-nav__link">
    <span class="md-ellipsis">
      API Reference
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../GMM/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GMM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../clustering/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Clustering Models (BERTopic & Top2Vec)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ctm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Autoencoding Models (ZeroShotTM & CombinedTM)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../FASTopic/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FASTopic
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../encoders/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Encoders
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../vectorizers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Vectorizers
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../namers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Namers
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="keynmf">KeyNMF</h1>
<p>KeyNMF is a topic model that relies on contextually sensitive embeddings for keyword retrieval and term importance estimation,
while taking inspiration from classical matrix-decomposition approaches for extracting topics.</p>
<figure>
  <img src="../images/keynmf.png" width="90%" style="margin-left: auto;margin-right: auto;">
  <figcaption>Schematic overview of KeyNMF</figcaption>
</figure>

<p>Here's an example of how you can fit and interpret a KeyNMF model in the easiest way.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">turftopic</span><span class="w"> </span><span class="kn">import</span> <span class="n">KeyNMF</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">KeyNMF</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">encoder</span><span class="o">=</span><span class="s2">&quot;paraphrase-MiniLM-L3-v2&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">print_topics</span><span class="p">()</span>
</code></pre></div>
<div class="admonition question">
<p class="admonition-title">Which Embedding model should I use</p>
<ul>
<li>You should probably use KeyNMF with a <code>paraphrase-</code> type embedding model. These seem to perform best in most tasks. Some examples include:<ul>
<li><a href="https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L3-v2">paraphrase-MiniLM-L3-v2</a> - Absolutely tiny <img alt="🐭" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f42d.svg" title=":mouse:" /> </li>
<li><a href="https://huggingface.co/sentence-transformers/paraphrase-mpnet-base-v2">paraphrase-mpnet-base-v2</a> - High performance <img alt="🌟" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f31f.svg" title=":star2:" /></li>
<li><a href="https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2">paraphrase-multilingual-mpnet-base-v2</a> - Multilingual, high-performance <img alt="🌎" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f30e.svg" title=":earth_americas:" /> <img alt="🌟" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f31f.svg" title=":star2:" /></li>
</ul>
</li>
<li>KeyNMF works remarkably well with static models, which are incredibly fast, even on your laptop:<ul>
<li><a href="https://huggingface.co/sentence-transformers/static-retrieval-mrl-en-v1">sentence-transformers/static-retrieval-mrl-en-v1</a> - Blazing Fast <img alt="⚡" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a1.svg" title=":zap:" /> </li>
<li><a href="https://huggingface.co/sentence-transformers/static-similarity-mrl-multilingual-v1">sentence-transformers/static-similarity-mrl-multilingual-v1</a> - Multilingual, Blazing Fast <img alt="🌎" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f30e.svg" title=":earth_americas:" /> <img alt="⚡" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a1.svg" title=":zap:" /> </li>
</ul>
</li>
</ul>
</div>
<h2 id="how-does-keynmf-work">How does KeyNMF work?</h2>
<h4 id="keyword-extraction">Keyword Extraction</h4>
<p>KeyNMF discovers topics based on the importances of keywords for a given document.
This is done by embedding words in a document, and then extracting the cosine similarities of documents to words using a transformer-model.
Only the <code>top_n</code> keywords with positive similarity are kept.</p>
<details class="info">
<summary>Click to see formula</summary>
<ul>
<li>
<ol>
<li>Let <span class="arithmatex">\(x_d\)</span> be the document's embedding produced with the encoder model.</li>
<li>
<ol>
<li>Let <span class="arithmatex">\(v_w\)</span> be the word's embedding produced with the encoder model.</li>
<li>Calculate cosine similarity between word and document</li>
</ol>
<p>For each word <span class="arithmatex">\(w\)</span> in the document <span class="arithmatex">\(d\)</span>:</p>
<div class="arithmatex">\[
\text{sim}(d, w) = \frac{x_d \cdot v_w}{||x_d|| \cdot ||v_w||}
\]</div>
</li>
</ol>
<p>For each document <span class="arithmatex">\(d\)</span>:</p>
<ol>
<li>Let <span class="arithmatex">\(K_d\)</span> be the set of <span class="arithmatex">\(N\)</span> keywords with the highest cosine similarity to document <span class="arithmatex">\(d\)</span>.</li>
</ol>
<div class="arithmatex">\[
K_d = \text{argmax}_{K^*} \sum_{w \in K^*}\text{sim}(d,w)\text{, where }
|K_d| = N\text{, and } \\
w \in d
\]</div>
</li>
<li>
<p>Arrange positive keyword similarities into a keyword matrix <span class="arithmatex">\(M\)</span> where the rows represent documents, and columns represent unique keywords.</p>
<div class="arithmatex">\[
M_{dw} = 
\begin{cases}
\text{sim}(d,w), &amp; \text{if } w \in K_d \text{ and } \text{sim}(d,w) &gt; 0 \\
0, &amp; \text{otherwise}.
\end{cases}
\]</div>
</li>
</ul>
</details>
<p>You can do this step manually if you want to precompute the keyword matrix.
Keywords are represented as dictionaries mapping words to keyword importances.</p>
<div class="highlight"><pre><span></span><code><span class="n">model</span><span class="o">.</span><span class="n">extract_keywords</span><span class="p">([</span><span class="s2">&quot;Cars are perhaps the most important invention of the last couple of centuries. They have revolutionized transportation in many ways.&quot;</span><span class="p">])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="p">[{</span><span class="s1">&#39;transportation&#39;</span><span class="p">:</span> <span class="mf">0.44713873</span><span class="p">,</span>
  <span class="s1">&#39;invention&#39;</span><span class="p">:</span> <span class="mf">0.560524</span><span class="p">,</span>
  <span class="s1">&#39;cars&#39;</span><span class="p">:</span> <span class="mf">0.5046208</span><span class="p">,</span>
  <span class="s1">&#39;revolutionized&#39;</span><span class="p">:</span> <span class="mf">0.3339205</span><span class="p">,</span>
  <span class="s1">&#39;important&#39;</span><span class="p">:</span> <span class="mf">0.21803442</span><span class="p">}]</span>
</code></pre></div>
<p>A precomputed Keyword matrix can also be used to fit a model:</p>
<div class="highlight"><pre><span></span><code><span class="n">keyword_matrix</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">extract_keywords</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">keywords</span><span class="o">=</span><span class="n">keyword_matrix</span><span class="p">)</span>
</code></pre></div>
<h4 id="topic-discovery">Topic Discovery</h4>
<p>Topics in this matrix are then discovered using Non-negative Matrix Factorization.
Essentially the model tries to discover underlying dimensions/factors along which most of the variance in term importance
can be explained.</p>
<details class="info">
<summary>Click to see formula</summary>
<ul>
<li>
<p>Decompose <span class="arithmatex">\(M\)</span> with non-negative matrix factorization: <span class="arithmatex">\(M \approx WH\)</span>, where <span class="arithmatex">\(W\)</span> is the document-topic matrix, and <span class="arithmatex">\(H\)</span> is the topic-term matrix. Non-negative Matrix Factorization is done with the coordinate-descent algorithm, minimizing square loss:</p>
<div class="arithmatex">\[
L(W,H) = ||M - WH||^2
\]</div>
</li>
</ul>
<p>You can fit KeyNMF on the raw corpus, with precomputed embeddings or with precomputed keywords.</p>
</details>
<div class="tabbed-set tabbed-alternate" data-tabs="1:3"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio" /><input id="__tabbed_1_2" name="__tabbed_1" type="radio" /><input id="__tabbed_1_3" name="__tabbed_1" type="radio" /><div class="tabbed-labels"><label for="__tabbed_1_1">Fitting on a corpus</label><label for="__tabbed_1_2">Pre-computed embeddings</label><label for="__tabbed_1_3">Pre-computed keyword matrix</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sentence_transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">SentenceTransformer</span>

<span class="n">trf</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s2">&quot;all-MiniLM-L6-v2&quot;</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">trf</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">KeyNMF</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">encoder</span><span class="o">=</span><span class="n">trf</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="n">keyword_matrix</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">extract_keywords</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">keywords</span><span class="o">=</span><span class="n">keyword_matrix</span><span class="p">)</span>
</code></pre></div>
</div>
</div>
</div>
<h2 id="seeded-topic-modeling">Seeded Topic Modeling</h2>
<p>When investigating a set of documents, you might already have an idea about what aspects you would like to explore.
In KeyNMF, you can describe this aspect, from which you want to investigate your corpus, using a free-text seed-phrase,
which will then be used to only extract topics, which are relevant to your research question.</p>
<details class="info">
<summary>How is this done?</summary>
<p>KeyNMF encodes the seed phrase into a seed-embedding.
Word importance scores in a document get weighted by their similarity to the seed-embedding.</p>
<ul>
<li>Embed seed-phrase into a seed-embedding: <span class="arithmatex">\(s\)</span></li>
<li>When extracting keywords from a document:<ol>
<li>Let <span class="arithmatex">\(x_d\)</span> be the document's embedding produced with the encoder model.</li>
<li>Let the document's relevance be <span class="arithmatex">\(r_d = \text{sim}(d,w)\)</span></li>
<li>For each word <span class="arithmatex">\(w\)</span>:<ol>
<li>Let the word's importance in the keyword matrix be: <span class="arithmatex">\(\text{sim}(d, w) \cdot r_d\)</span> if <span class="arithmatex">\(r_d &gt; 0\)</span>, otherwise <span class="arithmatex">\(0\)</span></li>
</ol>
</li>
</ol>
</li>
</ul>
</details>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">turftopic</span><span class="w"> </span><span class="kn">import</span> <span class="n">KeyNMF</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">KeyNMF</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">seed_phrase</span><span class="o">=</span><span class="s2">&quot;&lt;your seed phrase&gt;&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">print_topics</span><span class="p">()</span>
</code></pre></div>
<div class="tabbed-set tabbed-alternate" data-tabs="2:3"><input checked="checked" id="__tabbed_2_1" name="__tabbed_2" type="radio" /><input id="__tabbed_2_2" name="__tabbed_2" type="radio" /><input id="__tabbed_2_3" name="__tabbed_2" type="radio" /><div class="tabbed-labels"><label for="__tabbed_2_1"><code>'Is the death penalty moral?'</code></label><label for="__tabbed_2_2"><code>'Evidence for the existence of god'</code></label><label for="__tabbed_2_3"><code>'Operating system kernels'</code></label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<table>
<thead>
<tr>
<th>Topic ID</th>
<th>Highest Ranking</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>morality, moral, immoral, morals, objective, morally, animals, society, species, behavior</td>
</tr>
<tr>
<td>1</td>
<td>armenian, armenians, genocide, armenia, turkish, turks, soviet, massacre, azerbaijan, kurdish</td>
</tr>
<tr>
<td>2</td>
<td>murder, punishment, death, innocent, penalty, kill, crime, moral, criminals, executed</td>
</tr>
<tr>
<td>3</td>
<td>gun, guns, firearms, crime, handgun, firearm, weapons, handguns, law, criminals</td>
</tr>
<tr>
<td>4</td>
<td>jews, israeli, israel, god, jewish, christians, sin, christian, palestinians, christianity</td>
</tr>
</tbody>
</table>
</div>
<div class="tabbed-block">
<table>
<thead>
<tr>
<th>Topic ID</th>
<th>Highest Ranking</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>atheist, atheists, religion, religious, theists, beliefs, christianity, christian, religions, agnostic</td>
</tr>
<tr>
<td>1</td>
<td>bible, christians, christian, christianity, church, scripture, religion, jesus, faith, biblical</td>
</tr>
<tr>
<td>2</td>
<td>god, existence, exist, exists, universe, creation, argument, creator, believe, life</td>
</tr>
<tr>
<td>3</td>
<td>believe, faith, belief, evidence, blindly, believing, gods, believed, beliefs, convince</td>
</tr>
<tr>
<td>4</td>
<td>atheism, atheists, agnosticism, belief, arguments, believe, existence, alt, believing, argument</td>
</tr>
</tbody>
</table>
</div>
<div class="tabbed-block">
<table>
<thead>
<tr>
<th>Topic ID</th>
<th>Highest Ranking</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>windows, dos, os, microsoft, ms, apps, pc, nt, file, shareware</td>
</tr>
<tr>
<td>1</td>
<td>ram, motherboard, card, monitor, memory, cpu, vga, mhz, bios, intel</td>
</tr>
<tr>
<td>2</td>
<td>unix, os, linux, intel, systems, programming, applications, compiler, software, platform</td>
</tr>
<tr>
<td>3</td>
<td>disk, scsi, disks, drive, floppy, drives, dos, controller, cd, boot</td>
</tr>
<tr>
<td>4</td>
<td>software, mac, hardware, ibm, graphics, apple, computer, pc, modem, program</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<h2 id="dynamic-topic-modeling">Dynamic Topic Modeling</h2>
<p>KeyNMF is also capable of modeling topics over time.
This happens by fitting a KeyNMF model first on the entire corpus, then
fitting individual topic-term matrices using coordinate descent based on the document-topic and document-term matrices in the given time slices.</p>
<details class="info">
<summary>Click to see formula</summary>
<ol>
<li>Compute keyword matrix <span class="arithmatex">\(M\)</span> for the whole corpus.</li>
<li>Decompose <span class="arithmatex">\(M\)</span> with non-negative matrix factorization: <span class="arithmatex">\(M \approx WH\)</span>.</li>
<li>
<ol>
<li>Let <span class="arithmatex">\(W_t\)</span> be the document-topic proportions for documents in time slice <span class="arithmatex">\(t\)</span>, and <span class="arithmatex">\(M_t\)</span> be the keyword matrix for words in time slice <span class="arithmatex">\(t\)</span>.</li>
<li>Obtain the topic-term matrix for the time slice, by minimizing square loss using coordinate descent and fixing <span class="arithmatex">\(W_t\)</span>:</li>
</ol>
<p>For each time slice <span class="arithmatex">\(t\)</span>:</p>
<div class="arithmatex">\[
H_t = \text{argmin}_{H^{*}} ||M_t - W_t H^{*}||^2
\]</div>
</li>
</ol>
</details>
<p>Here's an example of using KeyNMF in a dynamic modeling setting:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">datetime</span><span class="w"> </span><span class="kn">import</span> <span class="n">datetime</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">turftopic</span><span class="w"> </span><span class="kn">import</span> <span class="n">KeyNMF</span>

<span class="n">corpus</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">timestamps</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">datetime</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">KeyNMF</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">top_n</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">document_topic_matrix</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_transform_dynamic</span><span class="p">(</span>
    <span class="n">corpus</span><span class="p">,</span> <span class="n">timestamps</span><span class="o">=</span><span class="n">timestamps</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span>
<span class="p">)</span>
</code></pre></div>
<p>You can use the <code>print_topics_over_time()</code> method for producing a table of the topics over the generated time slices.</p>
<blockquote>
<p>This example uses CNN news data.</p>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="n">model</span><span class="o">.</span><span class="n">print_topics_over_time</span><span class="p">()</span>
</code></pre></div>
<center>

| Time Slice | 0_olympics_tokyo_athletes_beijing | 1_covid_vaccine_pandemic_coronavirus | 2_olympic_athletes_ioc_athlete | 3_djokovic_novak_tennis_federer | 4_ronaldo_cristiano_messi_manchester |
| - | - | - | - | - | - |
| 2012 12 06 - 2013 11 10 | genocide, yugoslavia, karadzic, facts, cnn | cnn, russia, chechnya, prince, merkel | france, cnn, francois, hollande, bike | tennis, tournament, wimbledon, grass, courts | beckham, soccer, retired, david, learn |
| 2013 11 10 - 2014 10 14 | keith, stones, richards, musician, author | georgia, russia, conflict, 2008, cnn | civil, rights, hear, why, should | cnn, kidneys, traffickers, organ, nepal | ronaldo, cristiano, goalscorer, soccer, player |
|  |  | ... |  |  |  |
| 2020 05 07 - 2021 04 10 | olympics, beijing, xinjiang, ioc, boycott | covid, vaccine, coronavirus, pandemic, vaccination | olympic, japan, medalist, canceled, tokyo | djokovic, novak, tennis, federer, masterclass | ronaldo, cristiano, messi, juventus, barcelona |
| 2021 04 10 - 2022 03 16 | olympics, tokyo, athletes, beijing, medal | covid, pandemic, vaccine, vaccinated, coronavirus | olympic, athletes, ioc, medal, athlete | djokovic, novak, tennis, wimbledon, federer | ronaldo, cristiano, messi, manchester, scored |

</center>

<p>You can also display the topics over time on an interactive HTML figure.
The most important words for topics get revealed by hovering over them.</p>
<blockquote>
<p>You will need to install Plotly for this to work.</p>
</blockquote>
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>plotly
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">model</span><span class="o">.</span><span class="n">plot_topics_over_time</span><span class="p">()</span>
</code></pre></div>
<figure>
  <iframe src="../images/dynamic_keynmf.html", title="Topics over time", style="height:800px;width:1000px;padding:0px;border:none;"></iframe>
  <figcaption> Topics over time in a Dynamic KeyNMF model. </figcaption>
</figure>

<h2 id="hierarchical-topic-modeling">Hierarchical Topic Modeling</h2>
<p>When you suspect that subtopics might be present in the topics you find with the model, KeyNMF can be used to discover topics further down the hierarchy.</p>
<p>This is done by utilising a special case of <strong>weighted NMF</strong>, where documents are weighted by how high they score on the parent topic.</p>
<details class="info">
<summary>Click to see formula</summary>
<ol>
<li>Decompose keyword matrix <span class="arithmatex">\(M \approx WH\)</span></li>
<li>To find subtopics in topic <span class="arithmatex">\(j\)</span>, define document weights <span class="arithmatex">\(w\)</span> as the <span class="arithmatex">\(j\)</span>th column of <span class="arithmatex">\(W\)</span>.</li>
<li>Estimate subcomponents with <strong>wNMF</strong> <span class="arithmatex">\(M \approx \mathring{W} \mathring{H}\)</span> with document weight <span class="arithmatex">\(w\)</span><ol>
<li>Initialise <span class="arithmatex">\(\mathring{H}\)</span> and  <span class="arithmatex">\(\mathring{W}\)</span> randomly.</li>
<li>Perform multiplicative updates until convergence. <br>
    <span class="arithmatex">\(\mathring{W}^T = \mathring{W}^T \odot \frac{\mathring{H} \cdot (M^T \odot w)}{\mathring{H} \cdot \mathring{H}^T \cdot (\mathring{W}^T \odot w)}\)</span> <br>
    <span class="arithmatex">\(\mathring{H}^T = \mathring{H}^T \odot \frac{ (M^T \odot w)\cdot \mathring{W}}{\mathring{H}^T \cdot (\mathring{W}^T \odot w) \cdot \mathring{W}}\)</span></li>
</ol>
</li>
<li>To sufficiently differentiate the subcomponents from each other a pseudo-c-tf-idf weighting scheme is applied to <span class="arithmatex">\(\mathring{H}\)</span>:<ol>
<li><span class="arithmatex">\(\mathring{H} = \mathring{H}_{ij} \odot ln(1 + \frac{A}{1+\sum_k \mathring{H}_{kj}})\)</span>, where <span class="arithmatex">\(A\)</span> is the average of all elements in <span class="arithmatex">\(\mathring{H}\)</span></li>
</ol>
</li>
</ol>
</details>
<p>To create a hierarchical model, you can use the <code>hierarchy</code> property of the model.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># This divides each of the topics in the model to 3 subtopics.</span>
<span class="n">model</span><span class="o">.</span><span class="n">hierarchy</span><span class="o">.</span><span class="n">divide_children</span><span class="p">(</span><span class="n">n_subtopics</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">hierarchy</span><span class="p">)</span>
</code></pre></div>
<div style="background-color: #F5F5F5; padding: 10px; padding-left: 20px; padding-right: 20px;">
<tt style="font-size: 11pt">
<b>Root </b><br>
├── <b style="color: blue">0</b>: windows, dos, os, disk, card, drivers, file, pc, files, microsoft <br>
│   ├── <b style="color: magenta">0.0</b>: dos, file, disk, files, program, windows, disks, shareware, norton, memory <br>
│   ├── <b style="color: magenta">0.1</b>: os, unix, windows, microsoft, apps, nt, ibm, ms, os2, platform <br>
│   └── <b style="color: magenta">0.2</b>: card, drivers, monitor, driver, vga, ram, motherboard, cards, graphics, ati <br>
└── <b style="color: blue">1</b>: atheism, atheist, atheists, religion, christians, religious, belief, christian, god, beliefs <br>
.    ├── <b style="color: magenta">1.0</b>: atheism, alt, newsgroup, reading, faq, islam, questions, read, newsgroups, readers <br>
.    ├── <b style="color: magenta">1.1</b>: atheists, atheist, belief, theists, beliefs, religious, religion, agnostic, gods, religions <br>
.    └── <b style="color: magenta">1.2</b>: morality, bible, christian, christians, moral, christianity, biblical, immoral, god, religion <br>
</tt>
</div>

<p>For a detailed tutorial on hierarchical modeling click <a href="../hierarchical/">here</a>.</p>
<h2 id="cross-lingual-keynmf">Cross-lingual KeyNMF</h2>
<p>KeyNMF, by default, does not come with cross-lingual capabilities, since only words that appear in a document can be assigned to it as keywords.
We, however provide a term-matching scheme that allows you to match words across languages based on their cosine similarity in a multilingual embedding model.</p>
<p>This is done by:</p>
<ol>
<li>Computing a similarity matrix over terms.</li>
<li>Checking, which terms have similarity over a given threshold (<em>0.9</em> is the default)</li>
<li>Building a graph from these connections, and finding graph components.</li>
<li>Adding up term importances for terms that appear in the same component for all documents.</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.feature_extraction.text</span><span class="w"> </span><span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">turftopic</span><span class="w"> </span><span class="kn">import</span> <span class="n">KeyNMF</span>

<span class="c1"># Loading a parallel corpus</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span>
    <span class="s2">&quot;aiana94/polynews-parallel&quot;</span><span class="p">,</span> <span class="s2">&quot;deu_Latn-eng_Latn&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span>
<span class="p">)</span>
<span class="c1"># Subsampling</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">test_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">)[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span>
<span class="n">corpus</span> <span class="o">=</span> <span class="n">ds</span><span class="p">[</span><span class="s2">&quot;src&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">ds</span><span class="p">[</span><span class="s2">&quot;tgt&quot;</span><span class="p">]</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">KeyNMF</span><span class="p">(</span>
    <span class="mi">10</span><span class="p">,</span>
    <span class="n">cross_lingual</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">encoder</span><span class="o">=</span><span class="s2">&quot;paraphrase-multilingual-MiniLM-L12-v2&quot;</span><span class="p">,</span>
    <span class="n">vectorizer</span><span class="o">=</span><span class="n">CountVectorizer</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">print_topics</span><span class="p">()</span>
</code></pre></div>
<table>
<thead>
<tr>
<th>Topic ID</th>
<th>Highest Ranking</th>
</tr>
</thead>
<tbody>
<tr>
<td>...</td>
<td></td>
</tr>
<tr>
<td>15</td>
<td>africa-afrikanisch-african, media-medien-medienwirksam, schwarzwald-negroe-schwarzer, apartheid, difficulties-complicated-problems, kontinents-continent-kontinent, äthiopien-ethiopia, investitionen-investiert-investierenden, satire-satirical, hundred-100-1001</td>
</tr>
<tr>
<td>16</td>
<td>lawmaker-judges-gesetzliche, schutz-sicherheit-geschützt, an-success-eintreten, australian-australien-australischen, appeal-appealing-appeals, lawyer-lawyers-attorney, regeln-rule-rules, öffentlichkeit-öffentliche-publicly, terrorism-terroristischer-terrorismus, convicted</td>
</tr>
<tr>
<td>17</td>
<td>israels-israel-israeli, palästinensischen-palestinians-palestine, gay-lgbtq-gays, david, blockaden-blockades-blockade, stars-star-stelle, aviv, bombardieren-bombenexplosion-bombing, militärischer-army-military, kampfflugzeuge-warplanes</td>
</tr>
<tr>
<td>18</td>
<td>russischer-russlands-russischen, facebookbeitrag-facebook-facebooks, soziale-gesellschaftliche-sozialbauten, internetnutzer-internet, activism-aktivisten-activists, webseiten-web-site, isis, netzwerken-networks-netzwerk, vkontakte, media-medien-medienwirksam</td>
</tr>
<tr>
<td>19</td>
<td>bundesstaates-regierenden-regiert, chinesischen-chinesische-chinesisch, präsidentschaft-presidential-president, regions-region-regionen, demokratien-democratic-democracy, kapitalismus-capitalist-capitalism, staatsbürgerin-citizens-bürger, jemen-jemenitische-yemen, angolanischen-angola, media-medien-medienwirksam</td>
</tr>
</tbody>
</table>
<h2 id="online-topic-modeling">Online Topic Modeling</h2>
<p>KeyNMF can also be fitted in an online manner.
This is done by fitting NMF with batches of data instead of the whole dataset at once.</p>
<h4 id="use-cases">Use Cases:</h4>
<ol>
<li>You can use online fitting when you have <strong>very large corpora</strong> at hand, and it would be impractical to fit a model on it at once.</li>
<li>You have <strong>new data flowing in constantly</strong>, and need a model that can morph the topics based on the incoming data. You can also do this in a dynamic fashion.</li>
<li>You need to <strong>finetune</strong> an already fitted topic model to novel data.</li>
</ol>
<h4 id="batch-fitting">Batch Fitting</h4>
<p>We will use the batching function from the itertools recipes to produce batches.</p>
<blockquote>
<p>In newer versions of Python (&gt;=3.12) you can just <code>from itertools import batched</code></p>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">batched</span><span class="p">(</span><span class="n">iterable</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="s2">&quot;Batch data into lists of length n. The last batch may be shorter.&quot;</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;n must be at least one&quot;</span><span class="p">)</span>
    <span class="n">it</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">iterable</span><span class="p">)</span>
    <span class="k">while</span> <span class="n">batch</span> <span class="o">:=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">islice</span><span class="p">(</span><span class="n">it</span><span class="p">,</span> <span class="n">n</span><span class="p">)):</span>
        <span class="k">yield</span> <span class="n">batch</span>
</code></pre></div>
<p>You can fit a KeyNMF model to a very large corpus in batches like so:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">turftopic</span><span class="w"> </span><span class="kn">import</span> <span class="n">KeyNMF</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">KeyNMF</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">top_n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;some string&quot;</span><span class="p">,</span> <span class="s2">&quot;etc&quot;</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batched</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="mi">200</span><span class="p">):</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">partial_fit</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</code></pre></div>
<h4 id="precomputing-the-keyword-matrix">Precomputing the Keyword Matrix</h4>
<p>If you desire the best results, it might make sense for you to go over the corpus in multiple epochs:</p>
<div class="highlight"><pre><span></span><code><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batched</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="mi">200</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">partial_fit</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</code></pre></div>
<p>This is mildly inefficient, however, as the texts need to be encoded on every epoch, and keywords need to be extracted.
In such scenarios you might want to precompute and maybe even save the extracted keywords to disk using the <code>extract_keywords()</code> method.</p>
<p>Keywords are represented as dictionaries mapping words to keyword importances.</p>
<div class="highlight"><pre><span></span><code><span class="n">model</span><span class="o">.</span><span class="n">extract_keywords</span><span class="p">([</span><span class="s2">&quot;Cars are perhaps the most important invention of the last couple of centuries. They have revolutionized transportation in many ways.&quot;</span><span class="p">])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="p">[{</span><span class="s1">&#39;transportation&#39;</span><span class="p">:</span> <span class="mf">0.44713873</span><span class="p">,</span>
  <span class="s1">&#39;invention&#39;</span><span class="p">:</span> <span class="mf">0.560524</span><span class="p">,</span>
  <span class="s1">&#39;cars&#39;</span><span class="p">:</span> <span class="mf">0.5046208</span><span class="p">,</span>
  <span class="s1">&#39;revolutionized&#39;</span><span class="p">:</span> <span class="mf">0.3339205</span><span class="p">,</span>
  <span class="s1">&#39;important&#39;</span><span class="p">:</span> <span class="mf">0.21803442</span><span class="p">}]</span>
</code></pre></div>
<p>You can extract keywords in batches and save them to disk to a file format of your choice.
In this example I will use NDJSON because of its simplicity.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Iterable</span>

<span class="c1"># Here we are saving keywords to a JSONL/NDJSON file</span>
<span class="k">with</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;keywords.jsonl&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">keyword_file</span><span class="p">:</span>
    <span class="c1"># Doing this in batches is much more efficient than individual texts because</span>
    <span class="c1"># of the encoding.</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batched</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="mi">200</span><span class="p">):</span>
        <span class="n">batch_keywords</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">extract_keywords</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="c1"># We serialize each</span>
        <span class="k">for</span> <span class="n">keywords</span> <span class="ow">in</span> <span class="n">batch_keywords</span><span class="p">:</span>
            <span class="n">keyword_file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">keywords</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">stream_keywords</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Iterable</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;This function streams keywords from the file.&quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;keywords.jsonl&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">open</span><span class="p">()</span> <span class="k">as</span> <span class="n">keyword_file</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">keyword_file</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">keyword_stream</span> <span class="o">=</span> <span class="n">stream_keywords</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">keyword_batch</span> <span class="ow">in</span> <span class="n">batched</span><span class="p">(</span><span class="n">keyword_stream</span><span class="p">,</span> <span class="mi">200</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">partial_fit</span><span class="p">(</span><span class="n">keywords</span><span class="o">=</span><span class="n">keyword_batch</span><span class="p">)</span>
</code></pre></div>
<h3 id="dynamic-online-topic-modeling">Dynamic Online Topic Modeling</h3>
<p>KeyNMF can be online fitted in a dynamic manner as well.
This is useful when you have large corpora of text over time, or when you want to fit the model on future information flowing in
and want to analyze the topics' changes over time.</p>
<p>When using dynamic online topic modeling you have to predefine the time bins that you will use, as the model can't infer these from the data.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">datetime</span><span class="w"> </span><span class="kn">import</span> <span class="n">datetime</span>

<span class="c1"># We will bin by years in a period of 2020-2030</span>
<span class="n">bins</span> <span class="o">=</span> <span class="p">[</span><span class="n">datetime</span><span class="p">(</span><span class="n">year</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">month</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">day</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2020</span><span class="p">,</span> <span class="mi">2030</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
</code></pre></div>
<p>You can then online fit a dynamic topic model with <code>partial_fit_dynamic()</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">KeyNMF</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">top_n</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">corpus</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="o">...</span><span class="p">]</span>
<span class="n">timestamps</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">datetime</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="o">...</span><span class="p">]</span>

<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batched</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">timestamps</span><span class="p">)):</span>
    <span class="n">text_batch</span><span class="p">,</span> <span class="n">ts_batch</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">batch</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">partial_fit_dynamic</span><span class="p">(</span><span class="n">text_batch</span><span class="p">,</span> <span class="n">timestamps</span><span class="o">=</span><span class="n">ts_batch</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">)</span>
</code></pre></div>
<h2 id="asymmetric-and-instruction-tuned-embedding-models">Asymmetric and Instruction-tuned Embedding Models</h2>
<p>Some embedding models can be used together with prompting, or encode queries and passages differently.
This is important for KeyNMF, as it is explicitly based on keyword retrieval, and its performance can be substantially enhanced by using asymmetric or prompted embeddings.
Microsoft's E5 models are, for instance, all prompted by default, and it would be detrimental to performance not to do so yourself.</p>
<p>In these cases, you're better off NOT passing a string to Turftopic models, but explicitly loading the model using <code>sentence-transformers</code>.</p>
<p>Here's an example of using instruct models for keyword retrieval with KeyNMF.
In this case, documents will serve as the queries and words as the passages:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">turftopic</span><span class="w"> </span><span class="kn">import</span> <span class="n">KeyNMF</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sentence_transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">SentenceTransformer</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span>
    <span class="s2">&quot;intfloat/multilingual-e5-large-instruct&quot;</span><span class="p">,</span>
    <span class="n">prompts</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="s2">&quot;Instruct: Retrieve relevant keywords from the given document. Query: &quot;</span>
        <span class="s2">&quot;passage&quot;</span><span class="p">:</span> <span class="s2">&quot;Passage: &quot;</span>
    <span class="p">},</span>
    <span class="c1"># Make sure to set default prompt to query!</span>
    <span class="n">default_prompt_name</span><span class="o">=</span><span class="s2">&quot;query&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">KeyNMF</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">)</span>
</code></pre></div>
<p>And a regular, asymmetric example:</p>
<div class="highlight"><pre><span></span><code><span class="n">encoder</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span>
    <span class="s2">&quot;intfloat/e5-large-v2&quot;</span><span class="p">,</span>
    <span class="n">prompts</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="s2">&quot;query: &quot;</span>
        <span class="s2">&quot;passage&quot;</span><span class="p">:</span> <span class="s2">&quot;passage: &quot;</span>
    <span class="p">},</span>
    <span class="c1"># Make sure to set default prompt to query!</span>
    <span class="n">default_prompt_name</span><span class="o">=</span><span class="s2">&quot;query&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">KeyNMF</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">)</span>
</code></pre></div>
<p>Setting the default prompt to <code>query</code> is especially important, when you are precomputing embeddings, as <code>query</code> should always be your default prompt to embed documents with.</p>
<h2 id="api-reference">API Reference</h2>


<div class="doc doc-object doc-class">



<h3 id="turftopic.models.keynmf.KeyNMF" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>          <code>turftopic.models.keynmf.KeyNMF</code>


</h3>


  <div class="doc doc-contents first">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="turftopic.base.ContextualModel" href="../model_overview/#turftopic.base.ContextualModel">ContextualModel</a></code>, <code><a class="autorefs autorefs-internal" title="turftopic.dynamic.DynamicTopicModel" href="../dynamic/#turftopic.dynamic.DynamicTopicModel">DynamicTopicModel</a></code>, <code><a class="autorefs autorefs-internal" title="turftopic.multimodal.MultimodalModel" href="../multimodal/#turftopic.multimodal.MultimodalModel">MultimodalModel</a></code></p>

  
      <p>Extracts keywords from documents based on semantic similarity of
term encodings to document encodings.
Topics are then extracted with non-negative matrix factorization from
keywords' proximity to documents.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">turftopic</span><span class="w"> </span><span class="kn">import</span> <span class="n">KeyNMF</span>

<span class="n">corpus</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;some text&quot;</span><span class="p">,</span> <span class="s2">&quot;more text&quot;</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">KeyNMF</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">top_n</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">print_topics</span><span class="p">()</span>
</code></pre></div>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>n_components</code></td>
          <td>
                <code>int</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Number of topics.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>encoder</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[<span title="turftopic.base.Encoder">Encoder</span>, str, <a class="autorefs autorefs-internal" title="turftopic.encoders.multimodal.MultimodalEncoder" href="../multimodal/#turftopic.encoders.multimodal.MultimodalEncoder">MultimodalEncoder</a>]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Model to encode documents/terms, all-MiniLM-L6-v2 is the default.</p>
            </div>
          </td>
          <td>
                <code>&#39;sentence-transformers/all-MiniLM-L6-v2&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>vectorizer</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[<span title="sklearn.feature_extraction.text.CountVectorizer">CountVectorizer</span>]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Vectorizer used for term extraction.
Can be used to prune or filter the vocabulary.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>top_n</code></td>
          <td>
                <code>int</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Number of keywords to extract for each document.</p>
            </div>
          </td>
          <td>
                <code>25</code>
          </td>
        </tr>
        <tr>
          <td><code>random_state</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[int]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Random state to use so that results are exactly reproducible.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>metric</code></td>
          <td>
                <code><span title="typing.Literal">Literal</span>[&#39;cosine&#39;, &#39;dot&#39;]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Similarity metric to use for keyword extraction.</p>
            </div>
          </td>
          <td>
                <code>&#39;cosine&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>seed_phrase</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[str]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Describes an aspect of the corpus that the model should explore.
It can be a free-text query, such as
"Christian Denominations: Protestantism and Catholicism"</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>cross_lingual</code></td>
          <td>
                <code>bool</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Indicates whether KeyNMF should match terms across languages.
This is useful when you have a corpus containing multiple languages.</p>
            </div>
          </td>
          <td>
                <code>False</code>
          </td>
        </tr>
        <tr>
          <td><code>term_match_threshold</code></td>
          <td>
                <code>float</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Cosine similarity threshold for matching terms across languages.</p>
            </div>
          </td>
          <td>
                <code>0.9</code>
          </td>
        </tr>
    </tbody>
  </table>

            <details class="quote">
              <summary>Source code in <code>turftopic/models/keynmf.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">KeyNMF</span><span class="p">(</span><span class="n">ContextualModel</span><span class="p">,</span> <span class="n">DynamicTopicModel</span><span class="p">,</span> <span class="n">MultimodalModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Extracts keywords from documents based on semantic similarity of</span>
<span class="sd">    term encodings to document encodings.</span>
<span class="sd">    Topics are then extracted with non-negative matrix factorization from</span>
<span class="sd">    keywords&#39; proximity to documents.</span>

<span class="sd">    ```python</span>
<span class="sd">    from turftopic import KeyNMF</span>

<span class="sd">    corpus: list[str] = [&quot;some text&quot;, &quot;more text&quot;, ...]</span>

<span class="sd">    model = KeyNMF(10, top_n=10).fit(corpus)</span>
<span class="sd">    model.print_topics()</span>
<span class="sd">    ```</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_components: int</span>
<span class="sd">        Number of topics.</span>
<span class="sd">    encoder: str or SentenceTransformer</span>
<span class="sd">        Model to encode documents/terms, all-MiniLM-L6-v2 is the default.</span>
<span class="sd">    vectorizer: CountVectorizer, default None</span>
<span class="sd">        Vectorizer used for term extraction.</span>
<span class="sd">        Can be used to prune or filter the vocabulary.</span>
<span class="sd">    top_n: int, default 25</span>
<span class="sd">        Number of keywords to extract for each document.</span>
<span class="sd">    random_state: int, default None</span>
<span class="sd">        Random state to use so that results are exactly reproducible.</span>
<span class="sd">    metric: &quot;cosine&quot; or &quot;dot&quot;, default &quot;cosine&quot;</span>
<span class="sd">        Similarity metric to use for keyword extraction.</span>
<span class="sd">    seed_phrase: str, default None</span>
<span class="sd">        Describes an aspect of the corpus that the model should explore.</span>
<span class="sd">        It can be a free-text query, such as</span>
<span class="sd">        &quot;Christian Denominations: Protestantism and Catholicism&quot;</span>
<span class="sd">    cross_lingual: bool, default False</span>
<span class="sd">        Indicates whether KeyNMF should match terms across languages.</span>
<span class="sd">        This is useful when you have a corpus containing multiple languages.</span>
<span class="sd">    term_match_threshold: float, default 0.9</span>
<span class="sd">        Cosine similarity threshold for matching terms across languages.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n_components</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">encoder</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
            <span class="n">Encoder</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="n">MultimodalEncoder</span>
        <span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;sentence-transformers/all-MiniLM-L6-v2&quot;</span><span class="p">,</span>
        <span class="n">vectorizer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">CountVectorizer</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">top_n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">25</span><span class="p">,</span>
        <span class="n">random_state</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">metric</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;cosine&quot;</span><span class="p">,</span> <span class="s2">&quot;dot&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;cosine&quot;</span><span class="p">,</span>
        <span class="n">seed_phrase</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cross_lingual</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">term_match_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">=</span> <span class="n">n_components</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">top_n</span> <span class="o">=</span> <span class="n">top_n</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric</span> <span class="o">=</span> <span class="n">metric</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_has_custom_vectorizer</span> <span class="o">=</span> <span class="n">vectorizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">encoder</span> <span class="o">==</span> <span class="s2">&quot;sentence-transformers/all-MiniLM-L6-v2&quot;</span>
            <span class="p">)</span> <span class="ow">and</span> <span class="n">cross_lingual</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;all-MiniLM is incompatible with cross-lingual transfer, using paraphrase-multilingual-MiniLM-L12-v2.&quot;</span>
                <span class="p">)</span>
                <span class="n">encoder</span> <span class="o">=</span> <span class="s2">&quot;paraphrase-multilingual-MiniLM-L12-v2&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">encoder_</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="n">encoder</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">encoder_</span> <span class="o">=</span> <span class="n">encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">validate_encoder</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">vectorizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">default_vectorizer</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">vectorizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">KeywordNMF</span><span class="p">(</span>
            <span class="n">n_components</span><span class="o">=</span><span class="n">n_components</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">top_n</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">top_n</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">extractor</span> <span class="o">=</span> <span class="n">SBertKeywordExtractor</span><span class="p">(</span>
            <span class="n">top_n</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">top_n</span><span class="p">,</span>
            <span class="n">vectorizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="p">,</span>
            <span class="n">encoder</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder_</span><span class="p">,</span>
            <span class="n">metric</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">metric</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seed_phrase</span> <span class="o">=</span> <span class="n">seed_phrase</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seed_embedding</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed_phrase</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">seed_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder_</span><span class="o">.</span><span class="n">encode</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">seed_phrase</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cross_lingual</span> <span class="o">=</span> <span class="n">cross_lingual</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">term_match_threshold</span> <span class="o">=</span> <span class="n">term_match_threshold</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">extract_keywords</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">batch_or_document</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fitting</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Extracts keywords from a document or a batch of documents.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        batch_or_document: str | list[str]</span>
<span class="sd">            A single document or a batch of documents.</span>
<span class="sd">        embeddings: ndarray, optional</span>
<span class="sd">            Precomputed document embeddings.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch_or_document</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">batch_or_document</span> <span class="o">=</span> <span class="p">[</span><span class="n">batch_or_document</span><span class="p">]</span>
        <span class="n">keywords</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extractor</span><span class="o">.</span><span class="n">batch_extract_keywords</span><span class="p">(</span>
            <span class="n">batch_or_document</span><span class="p">,</span>
            <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span><span class="p">,</span>
            <span class="n">seed_embedding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed_embedding</span><span class="p">,</span>
            <span class="n">fitting</span><span class="o">=</span><span class="n">fitting</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_lingual</span><span class="p">:</span>
            <span class="n">keywords</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extractor</span><span class="o">.</span><span class="n">match_terms</span><span class="p">(</span>
                <span class="n">keywords</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">term_match_threshold</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">keywords</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">vectorize</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">raw_documents</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">keywords</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">spr</span><span class="o">.</span><span class="n">csr_array</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Creates document-term-matrix from documents.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">keywords</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_keywords</span><span class="p">(</span>
                <span class="n">raw_documents</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">keywords</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">divide_topic</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">node</span><span class="p">:</span> <span class="n">DivisibleTopicNode</span><span class="p">,</span>
        <span class="n">n_subtopics</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">DivisibleTopicNode</span><span class="p">]:</span>
        <span class="n">document_term_matrix</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;document_term_matrix&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">document_term_matrix</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;document_term_matrix is needed for computing hierarchies. Perhaps you fitted the model online?&quot;</span>
            <span class="p">)</span>
        <span class="n">dtm</span> <span class="o">=</span> <span class="n">document_term_matrix</span>
        <span class="n">subtopics</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">document_topic_vector</span>
        <span class="n">subcomponents</span><span class="p">,</span> <span class="n">sub_doc_topic</span> <span class="o">=</span> <span class="n">weighted_nmf</span><span class="p">(</span>
            <span class="n">dtm</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">n_subtopics</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">200</span>
        <span class="p">)</span>
        <span class="n">subcomponents</span> <span class="o">=</span> <span class="n">subcomponents</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
            <span class="mi">1</span> <span class="o">+</span> <span class="n">subcomponents</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="n">subcomponents</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">subcomponents</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">subcomponents</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="s2">&quot;l2&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">component</span><span class="p">,</span> <span class="n">doc_topic_vector</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
            <span class="nb">range</span><span class="p">(</span><span class="n">n_subtopics</span><span class="p">),</span> <span class="n">subcomponents</span><span class="p">,</span> <span class="n">sub_doc_topic</span><span class="o">.</span><span class="n">T</span>
        <span class="p">):</span>
            <span class="n">sub</span> <span class="o">=</span> <span class="n">DivisibleTopicNode</span><span class="p">(</span>
                <span class="bp">self</span><span class="p">,</span>
                <span class="n">path</span><span class="o">=</span><span class="p">(</span><span class="o">*</span><span class="n">node</span><span class="o">.</span><span class="n">path</span><span class="p">,</span> <span class="n">i</span><span class="p">),</span>
                <span class="n">word_importance</span><span class="o">=</span><span class="n">component</span><span class="p">,</span>
                <span class="n">document_topic_vector</span><span class="o">=</span><span class="n">doc_topic_vector</span><span class="p">,</span>
                <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">subtopics</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sub</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">subtopics</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">fit_transform</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">raw_documents</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">keywords</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Fits topic model and returns topic importances for documents.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        raw_documents: iterable of str, optional</span>
<span class="sd">            Documents to fit the model on.</span>
<span class="sd">        embeddings: ndarray of shape (n_documents, n_dimensions), optional</span>
<span class="sd">            Precomputed document encodings.</span>
<span class="sd">        keywords: list[dict[str, float]], optional</span>
<span class="sd">            Precomputed keyword dictionaries.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ndarray of shape (n_dimensions, n_topics)</span>
<span class="sd">            Document-topic matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed_phrase</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Seed phrase is specified, but keyword matrix is pre-computed. The seed phrase will be ignored. Note that this is not a problem if you already calculated the keyword matrix using the seed phrase.&quot;</span>
            <span class="p">)</span>
        <span class="n">console</span> <span class="o">=</span> <span class="n">Console</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">console</span><span class="o">.</span><span class="n">status</span><span class="p">(</span><span class="s2">&quot;Running KeyNMF&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">status</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">status</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="s2">&quot;Extracting keywords&quot;</span><span class="p">)</span>
                <span class="n">keywords</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_keywords</span><span class="p">(</span>
                    <span class="n">raw_documents</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span>
                <span class="p">)</span>
                <span class="n">console</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;Keyword extraction done.&quot;</span><span class="p">)</span>
            <span class="n">status</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="s2">&quot;Decomposing with NMF&quot;</span><span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">doc_topic_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">keywords</span><span class="p">)</span>
            <span class="k">except</span> <span class="p">(</span><span class="n">NotFittedError</span><span class="p">,</span> <span class="ne">AttributeError</span><span class="p">):</span>
                <span class="n">doc_topic_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">keywords</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">components_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">components</span>
            <span class="n">console</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;Model fitting done.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">document_topic_matrix</span> <span class="o">=</span> <span class="n">doc_topic_matrix</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">document_term_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">keywords</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hierarchy</span> <span class="o">=</span> <span class="n">DivisibleTopicNode</span><span class="o">.</span><span class="n">create_root</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">components_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">document_topic_matrix</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">doc_topic_matrix</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">fit_transform_multimodal</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">raw_documents</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">images</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">ImageRepr</span><span class="p">],</span>
        <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MultimodalEmbeddings</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">validate_embeddings</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>
        <span class="n">console</span> <span class="o">=</span> <span class="n">Console</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">multimodal_embeddings</span> <span class="o">=</span> <span class="n">embeddings</span>
        <span class="k">with</span> <span class="n">console</span><span class="o">.</span><span class="n">status</span><span class="p">(</span><span class="s2">&quot;Fitting model&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">status</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multimodal_embeddings</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">status</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="s2">&quot;Encoding documents&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">multimodal_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode_multimodal</span><span class="p">(</span>
                    <span class="n">raw_documents</span><span class="p">,</span> <span class="n">images</span>
                <span class="p">)</span>
                <span class="n">console</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;Documents encoded.&quot;</span><span class="p">)</span>
            <span class="n">status</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="s2">&quot;Extracting keywords&quot;</span><span class="p">)</span>
            <span class="n">document_keywords</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_keywords</span><span class="p">(</span>
                <span class="n">raw_documents</span><span class="p">,</span>
                <span class="n">embeddings</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">multimodal_embeddings</span><span class="p">[</span><span class="s2">&quot;document_embeddings&quot;</span><span class="p">],</span>
            <span class="p">)</span>
            <span class="n">image_keywords</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_keywords</span><span class="p">(</span>
                <span class="n">raw_documents</span><span class="p">,</span>
                <span class="n">embeddings</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">multimodal_embeddings</span><span class="p">[</span><span class="s2">&quot;image_embeddings&quot;</span><span class="p">],</span>
            <span class="p">)</span>
            <span class="n">console</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;Keyword extraction done.&quot;</span><span class="p">)</span>
            <span class="n">status</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="s2">&quot;Decomposing with NMF&quot;</span><span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">doc_topic_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">document_keywords</span><span class="p">)</span>
            <span class="k">except</span> <span class="p">(</span><span class="n">NotFittedError</span><span class="p">,</span> <span class="ne">AttributeError</span><span class="p">):</span>
                <span class="n">doc_topic_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">document_keywords</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">components_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">components</span>
            <span class="n">console</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;Model fitting done.&quot;</span><span class="p">)</span>
            <span class="n">status</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="s2">&quot;Transforming images&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">image_topic_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">image_keywords</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">top_images</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">]]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">collect_top_images</span><span class="p">(</span>
                <span class="n">images</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_topic_matrix</span>
            <span class="p">)</span>
            <span class="n">console</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;Images transformed&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">document_topic_matrix</span> <span class="o">=</span> <span class="n">doc_topic_matrix</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">document_term_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">document_keywords</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hierarchy</span> <span class="o">=</span> <span class="n">DivisibleTopicNode</span><span class="o">.</span><span class="n">create_root</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">components_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">document_topic_matrix</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">doc_topic_matrix</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">raw_documents</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">keywords</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Fits topic model and returns topic importances for documents.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        raw_documents: iterable of str, optional</span>
<span class="sd">            Documents to fit the model on.</span>
<span class="sd">        embeddings: ndarray of shape (n_documents, n_dimensions), optional</span>
<span class="sd">            Precomputed document encodings.</span>
<span class="sd">        keywords: list[dict[str, float]], optional</span>
<span class="sd">            Precomputed keyword dictionaries.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span>
            <span class="n">raw_documents</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">keywords</span><span class="o">=</span><span class="n">keywords</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_vocab</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">index_to_key</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">transform</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">raw_documents</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">keywords</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Infers topic importances for new documents based on a fitted model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        raw_documents: iterable of str</span>
<span class="sd">            Documents to fit the model on.</span>
<span class="sd">        embeddings: ndarray of shape (n_documents, n_dimensions), optional</span>
<span class="sd">            Precomputed document encodings.</span>
<span class="sd">        keywords: list[dict[str, float]], optional</span>
<span class="sd">            Precomputed keyword dictionaries.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ndarray of shape (n_dimensions, n_topics)</span>
<span class="sd">            Document-topic matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed_phrase</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Seed phrase is specified, but keyword matrix is pre-computed. The seed phrase will be ignored. Note that this is not a problem if you already calculated the keyword matrix using the seed phrase.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">raw_documents</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;You have to pass either keywords or raw_documents.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">keywords</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_keywords</span><span class="p">(</span>
                <span class="nb">list</span><span class="p">(</span><span class="n">raw_documents</span><span class="p">),</span>
                <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span><span class="p">,</span>
                <span class="n">fitting</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">keywords</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">partial_fit</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">raw_documents</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">keywords</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Online fits KeyNMF on a batch of documents.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        raw_documents: iterable of str</span>
<span class="sd">            Documents to fit the model on.</span>
<span class="sd">        embeddings: ndarray of shape (n_documents, n_dimensions), optional</span>
<span class="sd">            Precomputed document encodings.</span>
<span class="sd">        keywords: list[dict[str, float]], optional</span>
<span class="sd">            Precomputed keyword dictionaries.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed_phrase</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Seed phrase is specified, but keyword matrix is pre-computed. The seed phrase will be ignored. Note that this is not a problem if you already calculated the keyword matrix using the seed phrase.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_lingual</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Cross-lingual online topic modeling is yet to be implemented in KeyNMF.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_custom_vectorizer</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">stop_words</span><span class="o">=</span><span class="s2">&quot;english&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_has_custom_vectorizer</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">min_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">min_df</span>
        <span class="n">max_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">max_df</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">min_df</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">max_df</span> <span class="o">!=</span> <span class="mf">1.0</span><span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;&quot;&quot;When applying partial fitting, the vectorizer is fitted batch-wise in KeyNMF.</span>
<span class="s2">            You have a vectorizer with min_df=</span><span class="si">{</span><span class="n">min_df</span><span class="si">}</span><span class="s2">, and max_df=</span><span class="si">{</span><span class="n">max_df</span><span class="si">}</span><span class="s2">.</span>
<span class="s2">            If you continue with these settings, all tokens might get filtered out.</span>
<span class="s2">            We recommend setting min_df=1 and max_df=1.0 for online fitting.</span>
<span class="s2">            `model = KeyNMF(10, vectorizer=CountVectorizer(min_df=1, max_df=1.0)`</span>
<span class="s2">            &quot;&quot;&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">raw_documents</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;You have to pass either keywords or raw_documents.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">keywords</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_keywords</span><span class="p">(</span>
                <span class="n">raw_documents</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">partial_fit</span><span class="p">(</span><span class="n">keywords</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">components_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">components</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">prepare_topic_data</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">corpus</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">keywords</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TopicData</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">corpus</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;You have to pass either keywords or raw_documents.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed_phrase</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Seed phrase is specified, but keyword matrix is pre-computed. The seed phrase will be ignored. Note that this is not a problem if you already calculated the keyword matrix using the seed phrase.&quot;</span>
            <span class="p">)</span>
        <span class="n">console</span> <span class="o">=</span> <span class="n">Console</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">console</span><span class="o">.</span><span class="n">status</span><span class="p">(</span><span class="s2">&quot;Running KeyNMF&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">status</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">embeddings</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode_documents</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">status</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="s2">&quot;Extracting keywords&quot;</span><span class="p">)</span>
                <span class="n">keywords</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_keywords</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span><span class="p">)</span>
                <span class="n">console</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;Keyword extraction done.&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">corpus</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">keywords</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">corpus</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;length of keywords is not the same as length of the corpus&quot;</span>
                <span class="p">)</span>
            <span class="n">status</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="s2">&quot;Decomposing with NMF&quot;</span><span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">doc_topic_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">keywords</span><span class="p">)</span>
            <span class="k">except</span> <span class="p">(</span><span class="n">NotFittedError</span><span class="p">,</span> <span class="ne">AttributeError</span><span class="p">):</span>
                <span class="n">doc_topic_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">keywords</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">components_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">components</span>
            <span class="n">console</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;Model fitting done.&quot;</span><span class="p">)</span>
            <span class="n">document_term_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">keywords</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">document_topic_matrix</span> <span class="o">=</span> <span class="n">doc_topic_matrix</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">document_term_matrix</span> <span class="o">=</span> <span class="n">document_term_matrix</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hierarchy</span> <span class="o">=</span> <span class="n">DivisibleTopicNode</span><span class="o">.</span><span class="n">create_root</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">components_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">document_topic_matrix</span>
        <span class="p">)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">TopicData</span><span class="p">(</span>
            <span class="n">corpus</span><span class="o">=</span><span class="n">corpus</span><span class="p">,</span>
            <span class="n">document_term_matrix</span><span class="o">=</span><span class="n">document_term_matrix</span><span class="p">,</span>
            <span class="n">vocab</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">get_vocab</span><span class="p">(),</span>
            <span class="n">document_topic_matrix</span><span class="o">=</span><span class="n">doc_topic_matrix</span><span class="p">,</span>
            <span class="n">document_representation</span><span class="o">=</span><span class="n">embeddings</span><span class="p">,</span>
            <span class="n">topic_term_matrix</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">components_</span><span class="p">,</span>  <span class="c1"># type: ignore</span>
            <span class="n">transform</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;transform&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
            <span class="n">topic_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">topic_names</span><span class="p">,</span>
            <span class="n">hierarchy</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;hierarchy&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">prepare_dynamic_topic_data</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">corpus</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">timestamps</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">datetime</span><span class="p">],</span>
        <span class="n">embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">bins</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">datetime</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
        <span class="n">keywords</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed_phrase</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Seed phrase is specified, but keyword matrix is pre-computed. The seed phrase will be ignored. Note that this is not a problem if you already calculated the keyword matrix using the seed phrase.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="p">((</span><span class="n">corpus</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">keywords</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">))</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">keywords</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Length of keywords is not the same as length of the corpus&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">corpus</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">keywords</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;You have to pass keywords or a corpus, but both are None.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">embeddings</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode_documents</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
        <span class="n">console</span> <span class="o">=</span> <span class="n">Console</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">console</span><span class="o">.</span><span class="n">status</span><span class="p">(</span><span class="s2">&quot;Running KeyNMF&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">status</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">embeddings</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode_documents</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">status</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="s2">&quot;Extracting keywords&quot;</span><span class="p">)</span>
                <span class="n">keywords</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_keywords</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span><span class="p">)</span>
                <span class="n">console</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;Keyword extraction done.&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">corpus</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">keywords</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">corpus</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;length of keywords is not the same as length of the corpus&quot;</span>
                <span class="p">)</span>
            <span class="n">status</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="s2">&quot;Decomposing with NMF&quot;</span><span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">doc_topic_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">keywords</span><span class="p">)</span>
            <span class="k">except</span> <span class="p">(</span><span class="n">NotFittedError</span><span class="p">,</span> <span class="ne">AttributeError</span><span class="p">):</span>
                <span class="n">doc_topic_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_transform_dynamic</span><span class="p">(</span>
                    <span class="n">corpus</span><span class="p">,</span>
                    <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span><span class="p">,</span>
                    <span class="n">keywords</span><span class="o">=</span><span class="n">keywords</span><span class="p">,</span>
                    <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span>
                    <span class="n">timestamps</span><span class="o">=</span><span class="n">timestamps</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="n">console</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;Model fitting done.&quot;</span><span class="p">)</span>
            <span class="n">document_term_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">keywords</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">classes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="n">classes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">components_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">TopicData</span><span class="p">(</span>
            <span class="n">corpus</span><span class="o">=</span><span class="n">corpus</span><span class="p">,</span>
            <span class="n">document_term_matrix</span><span class="o">=</span><span class="n">document_term_matrix</span><span class="p">,</span>
            <span class="n">vocab</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">get_vocab</span><span class="p">(),</span>
            <span class="n">document_topic_matrix</span><span class="o">=</span><span class="n">doc_topic_matrix</span><span class="p">,</span>
            <span class="n">document_representation</span><span class="o">=</span><span class="n">embeddings</span><span class="p">,</span>
            <span class="n">topic_term_matrix</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">components_</span><span class="p">,</span>  <span class="c1"># type: ignore</span>
            <span class="n">transform</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;transform&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
            <span class="n">topic_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">topic_names</span><span class="p">,</span>
            <span class="n">classes</span><span class="o">=</span><span class="n">classes</span><span class="p">,</span>
            <span class="n">temporal_components</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">temporal_components_</span><span class="p">,</span>
            <span class="n">temporal_importance</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">temporal_importance_</span><span class="p">,</span>
            <span class="n">time_bin_edges</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">time_bin_edges</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">fit_transform_dynamic</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">raw_documents</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">timestamps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">datetime</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">keywords</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">bins</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">datetime</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed_phrase</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Seed phrase is specified, but keyword matrix is pre-computed. The seed phrase will be ignored. Note that this is not a problem if you already calculated the keyword matrix using the seed phrase.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">timestamps</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;You have to pass timestamps when fitting a dynamic model.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">raw_documents</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;You have to pass either keywords or raw_documents.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">keywords</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_keywords</span><span class="p">(</span>
                <span class="n">raw_documents</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span>
            <span class="p">)</span>
        <span class="n">time_labels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_bin_edges</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bin_timestamps</span><span class="p">(</span>
            <span class="n">timestamps</span><span class="p">,</span> <span class="n">bins</span>
        <span class="p">)</span>
        <span class="n">doc_topic_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit_transform_dynamic</span><span class="p">(</span>
            <span class="n">keywords</span><span class="p">,</span> <span class="n">time_labels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_bin_edges</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temporal_importance_</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">temporal_importance_</span><span class="o">.</span><span class="n">T</span>
            <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">temporal_importance_</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temporal_components_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">temporal_components</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">components_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">components</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">document_topic_matrix</span> <span class="o">=</span> <span class="n">doc_topic_matrix</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">document_term_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">keywords</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hierarchy</span> <span class="o">=</span> <span class="n">DivisibleTopicNode</span><span class="o">.</span><span class="n">create_root</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">components_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">document_topic_matrix</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">doc_topic_matrix</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">partial_fit_dynamic</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">raw_documents</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">timestamps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">datetime</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">keywords</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">bins</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">datetime</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Online fits Dynamic KeyNMF on a batch of documents.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        raw_documents: iterable of str</span>
<span class="sd">            Documents to fit the model on.</span>
<span class="sd">        embeddings: ndarray of shape (n_documents, n_dimensions), optional</span>
<span class="sd">            Precomputed document encodings.</span>
<span class="sd">        keywords: list[dict[str, float]], optional</span>
<span class="sd">            Precomputed keyword dictionaries.</span>
<span class="sd">        timestamps: list[datetime], optional</span>
<span class="sd">            List of timestamps for the batch.</span>
<span class="sd">        bins: list[datetime]</span>
<span class="sd">            Explicit time bin edges for the dynamic model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed_phrase</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Seed phrase is specified, but keyword matrix is pre-computed. The seed phrase will be ignored. Note that this is not a problem if you already calculated the keyword matrix using the seed phrase.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_lingual</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Cross-lingual online topic modeling is yet to be implemented in KeyNMF.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">timestamps</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;You have to pass timestamps when fitting a dynamic model.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">raw_documents</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;You have to pass either keywords or raw_documents.&quot;</span>
            <span class="p">)</span>
        <span class="n">time_bin_edges</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;time_bin_edges&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">time_bin_edges</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="s2">&quot;You have to pass explicit time bins (list of time bin edges) when partial &quot;</span>
                    <span class="s2">&quot;fitting KeyNMF, at least at the first call.&quot;</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">time_bin_edges</span> <span class="o">=</span> <span class="n">bins</span>
        <span class="n">time_labels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_bin_edges</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bin_timestamps</span><span class="p">(</span>
            <span class="n">timestamps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_bin_edges</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">keywords</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_keywords</span><span class="p">(</span>
                <span class="n">raw_documents</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">partial_fit_dynamic</span><span class="p">(</span>
            <span class="n">keywords</span><span class="p">,</span> <span class="n">time_labels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_bin_edges</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temporal_importance_</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">temporal_importance_</span><span class="o">.</span><span class="n">T</span>
            <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">temporal_importance_</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temporal_components_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">temporal_components</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">components_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">components</span>
        <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h4 id="turftopic.models.keynmf.KeyNMF.extract_keywords" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>          <code class="highlight language-python"><span class="n">extract_keywords</span><span class="p">(</span><span class="n">batch_or_document</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">fitting</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Extracts keywords from a document or a batch of documents.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>batch_or_document</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[str, list[str]]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>A single document or a batch of documents.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>embeddings</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[<span title="numpy.ndarray">ndarray</span>]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Precomputed document embeddings.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>turftopic/models/keynmf.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">extract_keywords</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">batch_or_document</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">fitting</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Extracts keywords from a document or a batch of documents.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    batch_or_document: str | list[str]</span>
<span class="sd">        A single document or a batch of documents.</span>
<span class="sd">    embeddings: ndarray, optional</span>
<span class="sd">        Precomputed document embeddings.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch_or_document</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">batch_or_document</span> <span class="o">=</span> <span class="p">[</span><span class="n">batch_or_document</span><span class="p">]</span>
    <span class="n">keywords</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extractor</span><span class="o">.</span><span class="n">batch_extract_keywords</span><span class="p">(</span>
        <span class="n">batch_or_document</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span><span class="p">,</span>
        <span class="n">seed_embedding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed_embedding</span><span class="p">,</span>
        <span class="n">fitting</span><span class="o">=</span><span class="n">fitting</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_lingual</span><span class="p">:</span>
        <span class="n">keywords</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extractor</span><span class="o">.</span><span class="n">match_terms</span><span class="p">(</span>
            <span class="n">keywords</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">term_match_threshold</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">keywords</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="turftopic.models.keynmf.KeyNMF.fit" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>          <code class="highlight language-python"><span class="n">fit</span><span class="p">(</span><span class="n">raw_documents</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keywords</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Fits topic model and returns topic importances for documents.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>raw_documents</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Documents to fit the model on.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>embeddings</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[<span title="numpy.ndarray">ndarray</span>]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Precomputed document encodings.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>keywords</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[list[dict[str, float]]]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Precomputed keyword dictionaries.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>turftopic/models/keynmf.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">raw_documents</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">keywords</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Fits topic model and returns topic importances for documents.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    raw_documents: iterable of str, optional</span>
<span class="sd">        Documents to fit the model on.</span>
<span class="sd">    embeddings: ndarray of shape (n_documents, n_dimensions), optional</span>
<span class="sd">        Precomputed document encodings.</span>
<span class="sd">    keywords: list[dict[str, float]], optional</span>
<span class="sd">        Precomputed keyword dictionaries.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span>
        <span class="n">raw_documents</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">keywords</span><span class="o">=</span><span class="n">keywords</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="turftopic.models.keynmf.KeyNMF.fit_transform" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>          <code class="highlight language-python"><span class="n">fit_transform</span><span class="p">(</span><span class="n">raw_documents</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keywords</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Fits topic model and returns topic importances for documents.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>raw_documents</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Documents to fit the model on.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>embeddings</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[<span title="numpy.ndarray">ndarray</span>]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Precomputed document encodings.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>keywords</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[list[dict[str, float]]]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Precomputed keyword dictionaries.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>



  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>ndarray of shape (n_dimensions, n_topics)</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Document-topic matrix.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>turftopic/models/keynmf.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">fit_transform</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">raw_documents</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">keywords</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Fits topic model and returns topic importances for documents.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    raw_documents: iterable of str, optional</span>
<span class="sd">        Documents to fit the model on.</span>
<span class="sd">    embeddings: ndarray of shape (n_documents, n_dimensions), optional</span>
<span class="sd">        Precomputed document encodings.</span>
<span class="sd">    keywords: list[dict[str, float]], optional</span>
<span class="sd">        Precomputed keyword dictionaries.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ndarray of shape (n_dimensions, n_topics)</span>
<span class="sd">        Document-topic matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed_phrase</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;Seed phrase is specified, but keyword matrix is pre-computed. The seed phrase will be ignored. Note that this is not a problem if you already calculated the keyword matrix using the seed phrase.&quot;</span>
        <span class="p">)</span>
    <span class="n">console</span> <span class="o">=</span> <span class="n">Console</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">console</span><span class="o">.</span><span class="n">status</span><span class="p">(</span><span class="s2">&quot;Running KeyNMF&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">status</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">status</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="s2">&quot;Extracting keywords&quot;</span><span class="p">)</span>
            <span class="n">keywords</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_keywords</span><span class="p">(</span>
                <span class="n">raw_documents</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span>
            <span class="p">)</span>
            <span class="n">console</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;Keyword extraction done.&quot;</span><span class="p">)</span>
        <span class="n">status</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="s2">&quot;Decomposing with NMF&quot;</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">doc_topic_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">keywords</span><span class="p">)</span>
        <span class="k">except</span> <span class="p">(</span><span class="n">NotFittedError</span><span class="p">,</span> <span class="ne">AttributeError</span><span class="p">):</span>
            <span class="n">doc_topic_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">keywords</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">components_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">components</span>
        <span class="n">console</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;Model fitting done.&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">document_topic_matrix</span> <span class="o">=</span> <span class="n">doc_topic_matrix</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">document_term_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">keywords</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">hierarchy</span> <span class="o">=</span> <span class="n">DivisibleTopicNode</span><span class="o">.</span><span class="n">create_root</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">components_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">document_topic_matrix</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">doc_topic_matrix</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="turftopic.models.keynmf.KeyNMF.partial_fit" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>          <code class="highlight language-python"><span class="n">partial_fit</span><span class="p">(</span><span class="n">raw_documents</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keywords</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Online fits KeyNMF on a batch of documents.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>raw_documents</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[list[str]]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Documents to fit the model on.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>embeddings</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[<span title="numpy.ndarray">ndarray</span>]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Precomputed document encodings.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>keywords</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[list[dict[str, float]]]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Precomputed keyword dictionaries.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>turftopic/models/keynmf.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">partial_fit</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">raw_documents</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">keywords</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Online fits KeyNMF on a batch of documents.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    raw_documents: iterable of str</span>
<span class="sd">        Documents to fit the model on.</span>
<span class="sd">    embeddings: ndarray of shape (n_documents, n_dimensions), optional</span>
<span class="sd">        Precomputed document encodings.</span>
<span class="sd">    keywords: list[dict[str, float]], optional</span>
<span class="sd">        Precomputed keyword dictionaries.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed_phrase</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;Seed phrase is specified, but keyword matrix is pre-computed. The seed phrase will be ignored. Note that this is not a problem if you already calculated the keyword matrix using the seed phrase.&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_lingual</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Cross-lingual online topic modeling is yet to be implemented in KeyNMF.&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_custom_vectorizer</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">stop_words</span><span class="o">=</span><span class="s2">&quot;english&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_has_custom_vectorizer</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">min_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">min_df</span>
    <span class="n">max_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">max_df</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">min_df</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">max_df</span> <span class="o">!=</span> <span class="mf">1.0</span><span class="p">):</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;&quot;&quot;When applying partial fitting, the vectorizer is fitted batch-wise in KeyNMF.</span>
<span class="s2">        You have a vectorizer with min_df=</span><span class="si">{</span><span class="n">min_df</span><span class="si">}</span><span class="s2">, and max_df=</span><span class="si">{</span><span class="n">max_df</span><span class="si">}</span><span class="s2">.</span>
<span class="s2">        If you continue with these settings, all tokens might get filtered out.</span>
<span class="s2">        We recommend setting min_df=1 and max_df=1.0 for online fitting.</span>
<span class="s2">        `model = KeyNMF(10, vectorizer=CountVectorizer(min_df=1, max_df=1.0)`</span>
<span class="s2">        &quot;&quot;&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">raw_documents</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;You have to pass either keywords or raw_documents.&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">keywords</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_keywords</span><span class="p">(</span>
            <span class="n">raw_documents</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span>
        <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">partial_fit</span><span class="p">(</span><span class="n">keywords</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">components_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">components</span>
    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="turftopic.models.keynmf.KeyNMF.partial_fit_dynamic" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>          <code class="highlight language-python"><span class="n">partial_fit_dynamic</span><span class="p">(</span><span class="n">raw_documents</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">timestamps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keywords</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Online fits Dynamic KeyNMF on a batch of documents.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>raw_documents</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Documents to fit the model on.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>embeddings</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[<span title="numpy.ndarray">ndarray</span>]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Precomputed document encodings.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>keywords</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[list[dict[str, float]]]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Precomputed keyword dictionaries.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>timestamps</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[list[<span title="datetime.datetime">datetime</span>]]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>List of timestamps for the batch.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>bins</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[int, list[<span title="datetime.datetime">datetime</span>]]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Explicit time bin edges for the dynamic model.</p>
            </div>
          </td>
          <td>
                <code>10</code>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>turftopic/models/keynmf.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">partial_fit_dynamic</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">raw_documents</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">timestamps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">datetime</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">keywords</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">bins</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">datetime</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Online fits Dynamic KeyNMF on a batch of documents.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    raw_documents: iterable of str</span>
<span class="sd">        Documents to fit the model on.</span>
<span class="sd">    embeddings: ndarray of shape (n_documents, n_dimensions), optional</span>
<span class="sd">        Precomputed document encodings.</span>
<span class="sd">    keywords: list[dict[str, float]], optional</span>
<span class="sd">        Precomputed keyword dictionaries.</span>
<span class="sd">    timestamps: list[datetime], optional</span>
<span class="sd">        List of timestamps for the batch.</span>
<span class="sd">    bins: list[datetime]</span>
<span class="sd">        Explicit time bin edges for the dynamic model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed_phrase</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;Seed phrase is specified, but keyword matrix is pre-computed. The seed phrase will be ignored. Note that this is not a problem if you already calculated the keyword matrix using the seed phrase.&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_lingual</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Cross-lingual online topic modeling is yet to be implemented in KeyNMF.&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">timestamps</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
            <span class="s2">&quot;You have to pass timestamps when fitting a dynamic model.&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">raw_documents</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;You have to pass either keywords or raw_documents.&quot;</span>
        <span class="p">)</span>
    <span class="n">time_bin_edges</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;time_bin_edges&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">time_bin_edges</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;You have to pass explicit time bins (list of time bin edges) when partial &quot;</span>
                <span class="s2">&quot;fitting KeyNMF, at least at the first call.&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">time_bin_edges</span> <span class="o">=</span> <span class="n">bins</span>
    <span class="n">time_labels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_bin_edges</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bin_timestamps</span><span class="p">(</span>
        <span class="n">timestamps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_bin_edges</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">keywords</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_keywords</span><span class="p">(</span>
            <span class="n">raw_documents</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span>
        <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">partial_fit_dynamic</span><span class="p">(</span>
        <span class="n">keywords</span><span class="p">,</span> <span class="n">time_labels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_bin_edges</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">temporal_importance_</span> <span class="o">=</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">temporal_importance_</span><span class="o">.</span><span class="n">T</span>
        <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">temporal_importance_</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="p">)</span><span class="o">.</span><span class="n">T</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">temporal_components_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">temporal_components</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">components_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">components</span>
    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="turftopic.models.keynmf.KeyNMF.transform" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>          <code class="highlight language-python"><span class="n">transform</span><span class="p">(</span><span class="n">raw_documents</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keywords</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Infers topic importances for new documents based on a fitted model.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>raw_documents</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Documents to fit the model on.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>embeddings</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[<span title="numpy.ndarray">ndarray</span>]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Precomputed document encodings.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>keywords</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[list[dict[str, float]]]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Precomputed keyword dictionaries.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>



  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>ndarray of shape (n_dimensions, n_topics)</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Document-topic matrix.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>turftopic/models/keynmf.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">transform</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">raw_documents</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">keywords</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Infers topic importances for new documents based on a fitted model.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    raw_documents: iterable of str</span>
<span class="sd">        Documents to fit the model on.</span>
<span class="sd">    embeddings: ndarray of shape (n_documents, n_dimensions), optional</span>
<span class="sd">        Precomputed document encodings.</span>
<span class="sd">    keywords: list[dict[str, float]], optional</span>
<span class="sd">        Precomputed keyword dictionaries.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ndarray of shape (n_dimensions, n_topics)</span>
<span class="sd">        Document-topic matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed_phrase</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;Seed phrase is specified, but keyword matrix is pre-computed. The seed phrase will be ignored. Note that this is not a problem if you already calculated the keyword matrix using the seed phrase.&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">raw_documents</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;You have to pass either keywords or raw_documents.&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">keywords</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_keywords</span><span class="p">(</span>
            <span class="nb">list</span><span class="p">(</span><span class="n">raw_documents</span><span class="p">),</span>
            <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span><span class="p">,</span>
            <span class="n">fitting</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">keywords</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="turftopic.models.keynmf.KeyNMF.vectorize" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>          <code class="highlight language-python"><span class="n">vectorize</span><span class="p">(</span><span class="n">raw_documents</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keywords</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Creates document-term-matrix from documents.</p>

          <details class="quote">
            <summary>Source code in <code>turftopic/models/keynmf.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">vectorize</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">raw_documents</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">keywords</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">spr</span><span class="o">.</span><span class="n">csr_array</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Creates document-term-matrix from documents.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">keywords</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">keywords</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_keywords</span><span class="p">(</span>
            <span class="n">raw_documents</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">keywords</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["toc.integrate", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.path", "navigation.indexes", "toc.follow", "content.code.copy"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.e1c3ead8.min.js"></script>
      
        <script src="../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>